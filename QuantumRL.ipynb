{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuantumRL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NV8sEgIgZisp",
        "hnWqxby5ZfY_",
        "kfmGXb2TZWpw"
      ],
      "authorship_tag": "ABX9TyNb7M2rpLapDhCnoY1FwMmo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescomontagna/Quantum-Reinforcement-Learning/blob/main/QuantumRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNsunVDOmIM2"
      },
      "source": [
        "# Google QuantumAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDU__H-6mNf9"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YQgeiVZmK4_"
      },
      "source": [
        "try:\n",
        "    import cirq\n",
        "except ImportError:\n",
        "    print(\"installing cirq...\")\n",
        "    !pip install --quiet cirq\n",
        "    print(\"installed cirq.\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ05rJZRmPcL"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng8kY2AmmXQS"
      },
      "source": [
        "import cirq\n",
        "from cirq import Simulator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ywYaaLPmtL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETGJGzcDIxwC"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import cmath\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import cm\n",
        "from functools import reduce\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import ParameterGrid"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWCQSEmAOUI3"
      },
      "source": [
        "# Introduction\n",
        "## Problems\n",
        "- Since we can access the features, and know the transition probability from a state to another, this RL protocol is model based.\n",
        "Note that this is in contrast with the uncertainty about a quantum state from the observator point of view: an observator can only access the collapsed state, having no access to the amplitudes. \n",
        "\n",
        "In the paper Girolami sent me, they explicitly account for this fact, setting up a model free protocol.  \n",
        "\n",
        "\n",
        "## Reward\n",
        "Il principale problema è la formulzione della reward. per ora, l'unica soluzione tale da portare risultati accettabili è stata:\n",
        "- reward = \"grande\" per stato terminal\n",
        "- reward < 0 per stato non terminal  \n",
        "\n",
        "L'aggiunta di reward negativa a punire ogni step che non portasse a uno stato terminale, è stato cruciale. Infatti, ho usato altri tipi di reward, ma tutte fallimentari  \n",
        "- fidelity\n",
        "- fidelity per stato terminale, altrimenti 0\n",
        "- \"grande\" per stato terminale, altrimenti 0  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8rsT6Mr7Zy"
      },
      "source": [
        "## Off Policy\n",
        "Sono dovuto ricorrere a un'approccio off policy, in quanto un approccio on policy non garantiva esplorazione sufficiente in uno spazio di ricerca così vasto. I risultati erano fortemente limitati, la matrice dei weight non vedeva mai alcune azioni, il cui valore rimaneva 0 per ogni features. I risultati erano in media peggiori di un' approccio Random.  \n",
        "Andando a usare una bahaviour policy completamente randomica, e una target policy completamente greedy, i risultati sono notavolmente migliorati. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-LCGYpUPpTm"
      },
      "source": [
        "# Quantum Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV8sEgIgZisp"
      },
      "source": [
        "### Qubit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjboXlFWG5EK"
      },
      "source": [
        "class Qubit:\n",
        "  def __init__(self, amplitudes):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      amplitudes (np.array): amplitudes of the |0>, |1> vectors\n",
        "    \"\"\"\n",
        "    error = \"Error: sum of squared amplitudes must be = 1\"\n",
        "    assert math.isclose(reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, amplitudes)), 1, rel_tol = 1e-2), error\n",
        "    self._amplitudes = amplitudes\n",
        "\n",
        "  def qubit(self):\n",
        "    return self._amplitudes\n",
        "    \n",
        "\n",
        "class Basis(Qubit):\n",
        "  def __init__(self, index):\n",
        "    \"\"\"\n",
        "    Z operator Basis\n",
        "    Args:\n",
        "      index: index of the position = 1\n",
        "    \"\"\"\n",
        "    amplitudes = np.zeros((2, ))\n",
        "    amplitudes[index] += 1\n",
        "    super().__init__(amplitudes)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnWqxby5ZfY_"
      },
      "source": [
        "### Quantum State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRBaWNuZyhgp"
      },
      "source": [
        "class QuantumState:\n",
        "  def __init__(self, amplitudes): \n",
        "\n",
        "    # We assume computational basis\n",
        "    self._basis = {\n",
        "        '00': [Basis(0), Basis(0)],\n",
        "        '01': [Basis(0), Basis(1)],\n",
        "        '10': [Basis(1), Basis(0)],\n",
        "        '11': [Basis(1), Basis(1)],\n",
        "    }\n",
        "\n",
        "    a1, a2, a3, a4 = amplitudes\n",
        "    self._amplitudes = {\n",
        "        '00': a1,\n",
        "        '01': a2,\n",
        "        '10': a3,\n",
        "        '11': a4\n",
        "    }\n",
        "    \n",
        "    self._keys = list(self._basis.keys())\n",
        "\n",
        "    error = \"Error: sum of squared amplitudes must be = 1\"\n",
        "    val = reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, amplitudes))\n",
        "    assert math.isclose(val, 1, rel_tol = 1e-2), error + f\" instead is {val}\"\n",
        "\n",
        "  def get_amplitudes(self):\n",
        "    return np.array(list(self._amplitudes.values()))\n",
        "\n",
        "  def get_features(self):\n",
        "    real = np.real(list(self.get_amplitudes()))\n",
        "    imag = np.imag(list(self.get_amplitudes()))\n",
        "    return np.concatenate((real, imag))\n",
        "\n",
        "  def apply_gate(self, gate, inplace = False):\n",
        "    updated_amplitudes = gate.apply(self)\n",
        "    if inplace:\n",
        "      self._amplitudes = updated_amplitudes\n",
        "      return None\n",
        "\n",
        "    return QuantumState(list(updated_amplitudes.values()))\n",
        "\n",
        "  def fidelity_score(self, other):\n",
        "    # TODO: check on nielsen\n",
        "    # This implementation is from paper\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      other (QuantumState): measure the fidelity between self and another quantum state\n",
        "    Return:\n",
        "      fidelity (float): fidelity score between [0, 1]\n",
        "    \"\"\"\n",
        "    # Inner product can be computed in terms of matrix representation. Page 67 Nielsen-Chuang\n",
        "    return np.square(abs(np.matmul(np.conj(self.get_amplitudes()), other.get_amplitudes())))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rboUEAK3ZbWt"
      },
      "source": [
        "### Quantum Gates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HOc4Ouiockr"
      },
      "source": [
        "class QuantumGate:\n",
        "  def __init__(self, name, unitary, target):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "      unitary: 2x2 unitary operator\n",
        "      target: 0 or 1 to denote the qubit the matrix is acting on\n",
        "    \"\"\"\n",
        "    self._name = name\n",
        "    self._U = unitary.flatten()\n",
        "    self._target = target\n",
        "\n",
        "\n",
        "  def apply(self, quantum_state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      quantum_state (QuantumState): quantum state to which apply the quantum operator\n",
        "    Return:\n",
        "      updated (dict): didctionary with updated amplitudes\n",
        "    \"\"\"\n",
        "    # Directly implement update rule on the amplitudes for a 2 qubits case. \n",
        "    # NOTE: This approach is not scalable! Refine or use qiskit for more than 2 qubits\n",
        "    a_00, a_01, a_10, a_11 = quantum_state.get_amplitudes()\n",
        "    updated = dict()\n",
        "\n",
        "    if self._target == 0:\n",
        "      updated['00'] = self._U[0]*a_00 + self._U[1]*a_10\n",
        "      updated['01'] = self._U[0]*a_01 + self._U[1]*a_11\n",
        "      updated['10'] = self._U[2]*a_00 + self._U[3]*a_10\n",
        "      updated['11'] = self._U[2]*a_01 + self._U[3]*a_11\n",
        "\n",
        "    else:\n",
        "      updated['00'] = self._U[0]*a_00 + self._U[1]*a_01\n",
        "      updated['01'] = self._U[2]*a_00 + self._U[3]*a_01\n",
        "      updated['10'] = self._U[0]*a_10 + self._U[1]*a_11\n",
        "      updated['11'] = self._U[2]*a_10 + self._U[3]*a_11\n",
        "\n",
        "    # Check if amplitudes still satisfy condition\n",
        "    normalization = reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, updated.values()))\n",
        "    error = f\"Error: sum of squared amplitudes must be = 1.\\n Amplitudes: {list(updated.values())}, summing up to {normalization}\"\n",
        "    assert math.isclose(normalization, 1, rel_tol = 1e-2), error\n",
        "    \n",
        "    return updated\n",
        "\n",
        "\n",
        "class CNOT(QuantumGate):\n",
        "  def __init__(self, control):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      control (int): if 0, first qubit is the control, else second\n",
        "    Return:\n",
        "      result (QuantumState): quantum state with amplitudes modified\n",
        "    \"\"\"\n",
        "    self._control = control\n",
        "    super().__init__('cnot', np.array([[0, 1], [1, 0]]), 1-control)\n",
        "\n",
        "\n",
        "  def apply(self, quantum_state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      state (QuantumState): quantum state to which apply the quantum operator\n",
        "    Return:\n",
        "      result (QuantumState): quantum state with amplitudes modified\n",
        "    \"\"\"\n",
        "    # Directly implement update rule on the amplitudes for a 2 qubits case. \n",
        "    # NOTE: This approach is not scalable! Refine or use qiskit for more than 2 qubits\n",
        "    a_00, a_01, a_10, a_11 = quantum_state.get_amplitudes()\n",
        "    updated = dict()\n",
        "\n",
        "    if self._control == 0: # Then target = 2nd: if 1st qubit == 1, flip 2nd qubit.\n",
        "      updated['00'] = a_00\n",
        "      updated['01'] = a_01\n",
        "      updated['10'] = self._U[0]*a_10 + self._U[1]*a_11\n",
        "      updated['11'] = self._U[2]*a_10 + self._U[3]*a_11\n",
        "\n",
        "    if self._control == 1: # Then control = 1st: if 2nd qubit == 1, flip 1st qubit.\n",
        "      updated['00'] = self._U[0]*a_00 + self._U[1]*a_10\n",
        "      updated['01'] = self._U[0]*a_01 + self._U[1]*a_11\n",
        "      updated['10'] = a_10\n",
        "      updated['11'] = a_11\n",
        "\n",
        "    # Check if amplitudes still satisfy condition\n",
        "    normalization = reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, updated.values()))\n",
        "    error = f\"Error: sum of squared amplitudes must be = 1.\\n Amplitudes: {list(updated.values())}, summing up to {normalization}\"\n",
        "    assert math.isclose(normalization, 1, rel_tol = 1e-2), error\n",
        "    \n",
        "    return updated"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmGXb2TZWpw"
      },
      "source": [
        "### Gates List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pus5TovHiETW"
      },
      "source": [
        "class Gates:\n",
        "  def __init__(self):\n",
        "    gates = dict()\n",
        "    self._num_gates = 0\n",
        "\n",
        "    # Useful\n",
        "    targets = [0, 1]\n",
        "    j = 1j # complex unit\n",
        "\n",
        "    ########### CNOT ###########\n",
        "    gates['CNOT'] = CNOT(control = 0)\n",
        "    self._num_gates += 1\n",
        "\n",
        "    ########### Rotations ###########\n",
        "    angles_names = ['pi', '2pi/3', 'pi/2', 'pi/3', 'pi/4']\n",
        "    angles_values = (math.pi / 2) * np.array([1, 2/3, 1/2, 1/3, 1/4])\n",
        "    angles = {k:v for k,v in zip(angles_names, angles_values)}\n",
        "\n",
        "    # Rx\n",
        "    for name, theta in angles.items():\n",
        "      for t in targets:\n",
        "        key = 'Rx' + str(t) + '(' + name + ')'\n",
        "        gates[key] = QuantumGate(key, np.array([[math.cos(theta), -j*math.sin(theta)],\n",
        "                                                      [-j*math.sin(theta), math.cos(theta)]]), t)\n",
        "        self._num_gates += 1\n",
        "        \n",
        "    # Ry\n",
        "    for name, theta in angles.items():\n",
        "      for t in targets:\n",
        "        key = 'Ry' + str(t) + '(' + name + ')'\n",
        "        gates[key] = QuantumGate(key, np.array([[math.cos(theta), -math.sin(theta)],\n",
        "                                                      [math.sin(theta), math.cos(theta)]]), t)\n",
        "        self._num_gates += 1\n",
        "\n",
        "    # Rz\n",
        "    for name, theta in angles.items():\n",
        "      for t in targets:\n",
        "        key = 'Rz' + str(t) + '(' + name + ')'\n",
        "        gates[key] = QuantumGate(key, np.array([[cmath.exp(-j*theta), 0],\n",
        "                                                      [0, cmath.exp(j*theta)]]), t)\n",
        "        self._num_gates += 1\n",
        "\n",
        "    # Hadamard\n",
        "    # gates['H0'] = QuantumGate('Hadamard_0', math.sqrt(1/2)*np.array([[1, 1], [-1, 1]]), 0)\n",
        "    # gates['H1'] = QuantumGate('Hadamard_0', math.sqrt(1/2)*np.array([[1, 1], [-1, 1]]), 0)\n",
        "\n",
        "    self._keys = list(gates.keys())\n",
        "    self._gates = list(gates.values())\n",
        "\n",
        "  def num_gates(self):\n",
        "    return self._num_gates"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQvWLKKRgZR9"
      },
      "source": [
        "#### Google Gates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a4R9ebGj2rl"
      },
      "source": [
        "class GoogleGates: \n",
        "  def __init__(self, keys = list()):\n",
        "    PI = math.pi\n",
        "    self._keys = keys\n",
        "    self._gates = [\n",
        "                  (cirq.CNOT, None),\n",
        "                  (cirq.rx(PI), cirq.I),\n",
        "                  (cirq.I, cirq.rx(PI)),\n",
        "                  (cirq.rx(2*PI/3), cirq.I),\n",
        "                  (cirq.I, cirq.rx(2*PI/3)),\n",
        "                  (cirq.rx(PI/2), cirq.I),\n",
        "                  (cirq.I, cirq.rx(PI/2)),\n",
        "                  (cirq.rx(PI/3), cirq.I),\n",
        "                  (cirq.I, cirq.rx(PI/3)),\n",
        "                  (cirq.rx(PI/4), cirq.I),\n",
        "                  (cirq.I, cirq.rx(PI/4)),\n",
        "                  (cirq.ry(PI), cirq.I),\n",
        "                  (cirq.I, cirq.ry(PI)),\n",
        "                  (cirq.ry(2*PI/3), cirq.I),\n",
        "                  (cirq.I, cirq.ry(2*PI/3)),\n",
        "                  (cirq.ry(PI/2), cirq.I),\n",
        "                  (cirq.I, cirq.ry(PI/2)),\n",
        "                  (cirq.ry(PI/3), cirq.I),\n",
        "                  (cirq.I, cirq.ry(PI/3)),\n",
        "                  (cirq.ry(PI/4), cirq.I),\n",
        "                  (cirq.I, cirq.ry(PI/4)),\n",
        "                  (cirq.rz(PI), cirq.I),\n",
        "                  (cirq.I, cirq.rz(PI)),\n",
        "                  (cirq.rz(2*PI/3), cirq.I),\n",
        "                  (cirq.I, cirq.rz(2*PI/3)),\n",
        "                  (cirq.rz(PI/2), cirq.I),\n",
        "                  (cirq.I, cirq.rz(PI/2)),\n",
        "                  (cirq.rz(PI/3), cirq.I),\n",
        "                  (cirq.I, cirq.rz(PI/3)),\n",
        "                  (cirq.rz(PI/4), cirq.I),\n",
        "                  (cirq.I, cirq.rz(PI/4)),\n",
        "                  # (cirq.H, cirq.I),\n",
        "                  # (cirq.I, cirq.H),\n",
        "    ]\n",
        "\n",
        "\n",
        "  def num_gates(self):\n",
        "    return len(self._gates)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQJvflImPuhP"
      },
      "source": [
        "# RL Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aflbZWf75E7C"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL6bfPeCJSbl"
      },
      "source": [
        "class Environment:\n",
        "  def __init__(self, initial_state, target_state,\n",
        "               tolerance, negative_reward, positive_reward):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      initial_state (QuantumState): initial state of the system\n",
        "      target_state (QuantumState): target state of the system\n",
        "      tolerance (float): tolerance in terms of fidelity score\n",
        "    \"\"\"\n",
        "    self._initial_state = initial_state\n",
        "    self._target_state = target_state\n",
        "\n",
        "    self._tolerance = tolerance # tolerance in terms of fidelity between\n",
        "\n",
        "    self._quantum_gates, self._keys, self._num_gates = self.gates_set()\n",
        "\n",
        "    self._terminal_fidelity = 0 # used to retrieve the info at the end of an episode\n",
        "    self._terminal_state = None # used to retrieve the info at the end of an episode\n",
        "\n",
        "    self._negative_reward = negative_reward\n",
        "    self._positive_reward = positive_reward\n",
        "    \n",
        "    # Used to initialize Environment instance from scratch.\n",
        "    self.reset() \n",
        "\n",
        "    \n",
        "  def gates_set(self):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      gates._gates (List[QuantumGate]): return the list with available QuantumGate objects\n",
        "      gates._keys (Dict[String: Int]): dictionary mapping a gate to its action index\n",
        "      gates.num_gates() (int): number of available gates (actions)\n",
        "    \"\"\"\n",
        "    gates = Gates()\n",
        "    return gates._gates, gates._keys, gates.num_gates()\n",
        "\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"\n",
        "    Given a gate, apply it to self._state.\n",
        "    Set the reward, resulting state and discount.\n",
        "    Return these values, along with the information if the terminal state has been reached\n",
        "    Args:\n",
        "      action (int): action index to select a QuantumGate\n",
        "\n",
        "    Return:\n",
        "      reward, discount, next_state features, terminal\n",
        "    \"\"\"\n",
        "    # Get and apply action. next_state is a QuantumState\n",
        "    gate = self._quantum_gates[action]\n",
        "    next_state = self._state.apply_gate(gate)\n",
        "\n",
        "    # Compare new state and target\n",
        "    fidelity = next_state.fidelity_score(self._target_state)\n",
        "\n",
        "    # Assign reward based on state and fidelity\n",
        "    terminal = self.is_terminal(fidelity)\n",
        "\n",
        "    # Terminal state\n",
        "    if terminal:\n",
        "      reward = self._positive_reward\n",
        "      discount = 0.\n",
        "      self._terminal_fidelity = fidelity\n",
        "      self._terminal_state = next_state\n",
        "      self.reset()\n",
        "    else:\n",
        "      reward = self._negative_reward\n",
        "      discount = 0.9\n",
        "      self._state = next_state\n",
        "\n",
        "    # Return the features, not the state itself\n",
        "    return reward, discount, self.get_obs(), terminal\n",
        "\n",
        "\n",
        "  def is_terminal(self, fidelity):\n",
        "    \"\"\"\n",
        "    Check if, by a level of self.tolerance, state is terminal\n",
        "    \"\"\"\n",
        "    if fidelity > (1 - self._tolerance):\n",
        "      return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "  def get_obs(self):\n",
        "    return self._state.get_features()\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self._state = self._initial_state"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ZoAqcy3qkH"
      },
      "source": [
        "## Agent\n",
        "There is a bug I think, when I provide as next_state the initial state I\n",
        "- agent is in state self._state: a state contiguous to the terminal one, T, that we call S\n",
        "- the update is done for S wrt to next_state, which in this case is I, and not T as expected. There are 2 major drawbacks as consequence  \n",
        "One is that the update is done wrongly: r + g*q(I), but I here has not any sense\n",
        "Two is that I will never learn that this state is contiguous.\n",
        "\n",
        "Now, I have to reason about this, because I think in the assignment they used this approach, but better to write down this doubt.\n",
        "\n",
        "NO! This issue is fixed by putting discount = 0. Alright :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWp0UZ7q6VVF"
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.buffer = []\n",
        "  \n",
        "  def append_transition(self, transition):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      transition (tuple): (state, action, reward, discount, next state)\n",
        "    \"\"\"\n",
        "    self.buffer.append(transition)\n",
        "\n",
        "  def sample_transition(self):\n",
        "    return random.choice(self.buffer)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De-sHIvHwKra"
      },
      "source": [
        "# Least Square TD Agent: action value function approximation\n",
        "# implemented with gradient descent.\n",
        "class LSTDAgent:\n",
        "  def __init__(self, number_of_actions, number_of_features,\n",
        "      initial_state, step_size, num_offline_updates):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      initial_state: it is a feature vector!\n",
        "    \"\"\"\n",
        "    self._number_of_actions = number_of_actions\n",
        "    self._W = np.zeros((number_of_actions, number_of_features), dtype = np.float16)\n",
        "    self._step_size = step_size\n",
        "    self._initial_state = initial_state\n",
        "\n",
        "    self._num_offline_updates = num_offline_updates\n",
        "    self._replay_buffer = ReplayBuffer() # supervised dataset\n",
        "    self._step = 0\n",
        "\n",
        "    # St self._state to initial state and pick an action randomly\n",
        "    self.reset(True)\n",
        "\n",
        "\n",
        "  def behaviour_policy(self, state = None):\n",
        "    return random.choice(range(self._number_of_actions))\n",
        "\n",
        "\n",
        "  def q(self, state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      state (list): list of the amplitudes := features of the state\n",
        "    \"\"\"\n",
        "    return np.matmul(self._W, state)\n",
        "\n",
        "\n",
        "  def step(self, reward, discount, next_state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      next_state (list): list of the amplitude: these are already features, not a QuantumState instance\n",
        "      terminal (boolean): if next_state is the terminal state\n",
        "    \"\"\"\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    r = reward\n",
        "    next_s = next_state\n",
        "    g = discount\n",
        "\n",
        "    # print(f\"State: {s}\")\n",
        "    # print(f\"Next State: {next_s}\")\n",
        "    # print()\n",
        "    self._W[a] += self._step_size * (r + g * np.max(self.q(next_s)) - self.q(s)[a]) * s\n",
        "\n",
        "    # Experience replay\n",
        "    self._replay_buffer.append_transition((s, a, r, g, next_s))\n",
        "    for _ in range(self._num_offline_updates):\n",
        "      s, a, r, g, next_s = self._replay_buffer.sample_transition()\n",
        "      self._W[a] += self._step_size * (r + g * np.max(self.q(next_s)) - self.q(s)[a]) * s\n",
        "\n",
        "    next_a = self.behaviour_policy()\n",
        "    self._action = next_a\n",
        "    self._state = next_s\n",
        "    self._step += 1\n",
        "\n",
        "    return next_a\n",
        "\n",
        "\n",
        "  def inference(self, reward, discount, next_state):\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    r = reward\n",
        "    next_s = next_state\n",
        "    g = discount\n",
        "\n",
        "    next_a = np.argmax(self.q(next_s))\n",
        "    self._action = next_a\n",
        "    self._state = next_s\n",
        "\n",
        "    return next_a\n",
        "\n",
        "\n",
        "  def reset(self, random = False):\n",
        "    self._state = self._initial_state\n",
        "    if random:\n",
        "      self._action = self.behaviour_policy()\n",
        "    else:\n",
        "      self._action = np.argmax(self.q(self._state))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5_vQxz7Ke2s"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwKia38JvwL"
      },
      "source": [
        "def compare_circuits(circuit_gates, final_state, target_state, path = None):\n",
        "  \"\"\"\n",
        "  Compare results obtained by google gates vs my custom gates implementation\n",
        "  Args:\n",
        "    circuit_gates (List[int]): indices of the gates in the circuit defined by the agent\n",
        "    final_state (QuantumState): terminal state reached by the agent\n",
        "    target_state (QuantumState): target state of TD agent\n",
        "  \"\"\"\n",
        "  my_gates = Gates()\n",
        "  google_gates = GoogleGates(my_gates._keys)\n",
        "\n",
        "  # Google initialization\n",
        "  q0 = cirq.NamedQubit('q0')\n",
        "  q1 = cirq.NamedQubit('q1')\n",
        "  circuit = cirq.Circuit()\n",
        "  def basic_circuit(u0, u1):\n",
        "    if (u1 is not None):\n",
        "      yield u0(q0), u1(q1)\n",
        "    else:\n",
        "      yield u0(q0, q1)\n",
        "\n",
        "  # Create the circuit with both Google API and my implementation\n",
        "  q = QuantumState(np.array([1, 0, 0, 0]))\n",
        "  for idx in circuit_gates:\n",
        "    q = q.apply_gate(my_gates._gates[idx])\n",
        "    circuit.append(basic_circuit(*google_gates._gates[idx]))\n",
        "\n",
        "  # Simulate Google circuit - oracle\n",
        "  simulator = Simulator()\n",
        "  result = simulator.simulate(circuit, qubit_order=[q0, q1])\n",
        "\n",
        "  # Check coherence between approximate terminal states\n",
        "  assert np.all(np.around(q.get_amplitudes(), 3) == np.around(final_state.get_amplitudes(), 3)),\\\n",
        "   f\"Unexpected terminal state: got {np.around(q.get_amplitudes(), 3)} rather than {np.around(final_state.get_amplitudes(), 3)}\"\n",
        "\n",
        "  # Check coherence between Google result and mine\n",
        "  # assert np.all(np.around(q.get_amplitudes(), 3) == np.around(result.final_state_vector, 3)),\\\n",
        "  #  f\"Unexpected terminal state: got {np.around(q.get_amplitudes(), 3)} rather than {np.around(result.final_state_vector, 3)}\"\n",
        "\n",
        "  print(f\"Approximate state: {np.around(final_state.get_amplitudes(), 3)}\")\n",
        "  print(f\"Target state: {np.around(target_state.get_amplitudes(), 3)}\")\n",
        "  print(f\"Fidelity score: {target_state.fidelity_score(final_state)}. Number of gates: {len(circuit_gates)}\")\n",
        "\n",
        "  print(\"\")\n",
        "  print(circuit)\n",
        "\n",
        "  if path is not None:\n",
        "    logs(final_state, target_state, circuit_gates, circuit, path)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyWWqvKkQSMj"
      },
      "source": [
        "def get_quantum_state(tolerance, seed, i):\n",
        "  \"\"\"\n",
        "  Get a feasible set of amplitudes of a quantum state, \n",
        "  by applying a random number of random gates to the initial state |00>\n",
        "\n",
        "  Return:\n",
        "    amplitudes (np.array): list of new state amplitudes\n",
        "  \"\"\"\n",
        "  random.seed(seed + i)\n",
        "  np.random.seed(seed + i)\n",
        "\n",
        "  gates = GoogleGates()\n",
        "\n",
        "  # Circuit initialization\n",
        "  q0 = cirq.NamedQubit('q0')\n",
        "  q1 = cirq.NamedQubit('q1')\n",
        "  circuit = cirq.Circuit()\n",
        "  def basic_circuit(u0, u1):\n",
        "    if (u1 is not None):\n",
        "      yield u0(q0), u1(q1)\n",
        "    else:\n",
        "      yield u0(q0, q1)\n",
        "\n",
        "  is_next = True\n",
        "  while is_next:\n",
        "    idx = random.choice(range(gates.num_gates()))\n",
        "    circuit.append(basic_circuit(*gates._gates[idx]))\n",
        "    is_next = np.random.choice([True, False], p=[0.9, 0.1])\n",
        "\n",
        "  simulator = Simulator()\n",
        "  result = simulator.simulate(circuit, qubit_order=[q0, q1])\n",
        "\n",
        "  amplitudes = result.final_state_vector\n",
        "\n",
        "  # Check correctness of the new state\n",
        "  error = \"Error: sum of squared amplitudes must be = 1\"\n",
        "  val = reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, amplitudes))\n",
        "  assert math.isclose(val, 1, rel_tol = 1e-2), error + f\" instead is {val}\"\n",
        "\n",
        "  # If I am equal to the initial state\n",
        "  if QuantumState(amplitudes).fidelity_score(QuantumState(np.array([1, 0, 0, 0]))) > (1-tolerance):\n",
        "    get_quantum_state(tolerance, seed, i*100)\n",
        "\n",
        "  return amplitudes"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBEHNVrNmria"
      },
      "source": [
        "def logs(final_state, target_state, circuit_gates, circuit, path):\n",
        "  \"\"\"\n",
        "  extra: any extra information I want to include in the logging\n",
        "  \"\"\"\n",
        "  with open(path, 'a+') as f:\n",
        "    f.write(f\"Approximate state: {np.around(final_state.get_amplitudes(), 3)}\\n\")\n",
        "    f.write(f\"Target state: {np.around(target_state.get_amplitudes(), 3)}\\n\")\n",
        "    f.write(f\"Fidelity score: {target_state.fidelity_score(final_state)}. Number of gates: {len(circuit_gates)}\\n\")\n",
        "    f.write(f\"Gates List: \")\n",
        "    f.write(f\"{circuit_gates}\\n\")\n",
        "    f.write(f\"{circuit}\\n\\n\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFL1yPnM06xH"
      },
      "source": [
        "# Experiment Facade\n",
        "Class to handle experiments and visualization  \n",
        "- [X] run experiment\n",
        "- [ ] Allow for agent.q visualization for a state, providing labels to actions. This allow to see if very close states are associated to very close actions\n",
        "- [ ] Monitor number of steps as experience grow: is the agent actually learning good? ==> in this sense no, but this is because of local minima. I do not have guarantee to find a global optimum with gradient descent (verify)\n",
        "- [ ] Monitor the weights (see if I can find any meaning): need to put labels about actions ==> does an action focuses on an amplitudes subset as I would expect (e.g. if an amplitude is not touched by  gate, than I expect its weight value to be low\n",
        "- [X] Monitor fidelity score inside episodes --> add inference every N steps\n",
        "- [ ] Monitor impact of initial gate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfMBR8Ws0sqy"
      },
      "source": [
        "# Facade class to run experiment\n",
        "class Experiment:\n",
        "  def __init__(self, start_state, target_state, tolerance, number_of_episodes,\n",
        "               step_size, num_offline_updates, negative_reward, positive_reward):\n",
        "\n",
        "    self._env = Environment(QuantumState(start_state), QuantumState(target_state),\n",
        "                            tolerance, negative_reward, positive_reward)\n",
        "\n",
        "    number_of_actions = len(self._env._keys)\n",
        "    initial_features = self._env.get_obs()\n",
        "\n",
        "    self._agent = LSTDAgent(number_of_actions, len(initial_features), initial_features,\n",
        "                            step_size, num_offline_updates)\n",
        "    \n",
        "    self._number_of_episodes = number_of_episodes\n",
        "\n",
        "\n",
        "  def run_experiment(self):\n",
        "    \"\"\"\n",
        "    Run episodes, gathering statistics and updating user on console.\n",
        "    \"\"\"\n",
        "    min_steps = -1\n",
        "    min_gates = []\n",
        "    min_terminal_state = None\n",
        "    for episode in range(self._number_of_episodes):\n",
        "        self.run_episode()\n",
        "        gates, terminal_state = self.run_inference(episode)\n",
        "        if min_steps == -1 or len(gates) < min_steps:\n",
        "            min_steps = len(gates)\n",
        "            min_gates = gates\n",
        "            min_terminal_state = terminal_state\n",
        "\n",
        "    return min_gates, min_terminal_state\n",
        "\n",
        "\n",
        "  def run_episode(self):\n",
        "    \"\"\"\n",
        "    Run a single episode.\n",
        "    At the beginning of an episode we must guarantee\n",
        "    - initial state in the environment\n",
        "    - initial state in the agent\n",
        "    \"\"\"\n",
        "    terminal = False\n",
        "    action = self._agent._action\n",
        "    while not terminal:\n",
        "      reward, discount, next_s, terminal = self._env.step(action)\n",
        "      action = self._agent.step(reward, discount, next_s)\n",
        "\n",
        "    # Add a reset step below, to take first action\n",
        "    self._agent.reset()\n",
        "\n",
        "\n",
        "  def run_inference(self, episode):\n",
        "    \"\"\"\n",
        "    Run an episode using the optimal policy learned\n",
        "    \"\"\"\n",
        "    terminal = False\n",
        "    action = self._agent._action\n",
        "    gates = []\n",
        "    while not terminal and len(gates) <= 1000:\n",
        "      gates.append(action)\n",
        "      reward, discount, next_s, terminal = self._env.step(action)\n",
        "      action = self._agent.inference(reward, discount, next_s)\n",
        "\n",
        "    if not terminal:\n",
        "      return gates, self._env._state\n",
        "\n",
        "    max_gates = 20\n",
        "    if len(gates) < max_gates:\n",
        "      print(f\"Episode {episode}: inference completed in {len(gates)} steps. Fidelity score: {self._env._terminal_fidelity}\")\n",
        "\n",
        "    return gates, self._env._terminal_state\n",
        "\n",
        "  \n",
        "  def q_values(self):\n",
        "    \"\"\"\n",
        "    The function should plot, in a [0, 1] complex plane, the value function\n",
        "    on the z axis, for each of the 4 value of amplitude.\n",
        "    In order to get reasonable values and understand the effect of the amplitude\n",
        "    under analysis on the overall q_values, the remaining amplitudes values will \n",
        "    be set to the target amplitudes.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
        "\n",
        "    state = self._env._target_state\n",
        "    features = state.get_features()\n",
        "    x = np.linspace(0, 1, num=100)\n",
        "    y = np.linspace(0, 1, num=100)\n",
        "    grid = np.meshgrid\n",
        "    q = []\n",
        "    for i in x:\n",
        "      row = []\n",
        "      for k in y:\n",
        "        features[0] = i\n",
        "        features[0] = k\n",
        "        row.append(self._agent.q(features))\n",
        "      \n",
        "      q.append(row)\n",
        "\n",
        "    q = np.array(q)\n",
        "    surf = ax.plot_surface(x, y, np.squeeze(q[:, :, 0]), cmap=cm.coolwarm,\n",
        "                       linewidth=0, antialiased=False)\n",
        "    \n",
        "    # Add a color bar which maps values to colors.\n",
        "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YKa4MYQ0tUp"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhrdRkT2LaEE"
      },
      "source": [
        "## Random Target States"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN0SmXxG_LPx"
      },
      "source": [
        "- Need to tune all the parameters below. In particular, it is important to understand upt to which point we can decrease the tolerance.\n",
        "- Substitute TRAINING_EPISODES with number of training steps "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R5nEorB3kgW"
      },
      "source": [
        "TOLERANCE = 0.1\n",
        "TRAINING_EPISODES = 100\n",
        "STEP_SIZE = 0.0001\n",
        "NUM_OFFLINE_UPDATES = 0 # WAY WORSE IF != 0\n",
        "SEED = 100\n",
        "NUM_EXPERIMENTS = 10\n",
        "PATH = \"logs.txt\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxfbO_gNpdtC"
      },
      "source": [
        "with open(PATH, \"w+\") as f:\n",
        "  f.write(f\"TOLERANCE: {TOLERANCE}\\n\")\n",
        "  f.write(f\"TRAINING_EPISODES: {TRAINING_EPISODES}\\n\")\n",
        "  f.write(f\"STEP_SIZE: {STEP_SIZE}\\n\")\n",
        "  f.write(f\"NUM_OFFLINE_UPDATES: {NUM_OFFLINE_UPDATES}\\n\")\n",
        "  f.write(f\"SEED: {SEED}\\n\")\n",
        "  f.write(f\"NUM_EXPERIMENTS: {NUM_EXPERIMENTS}\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbXs0upGaB2d"
      },
      "source": [
        "TODO:\n",
        "- Best policy? Per ora, numero minimo di gates\n",
        "- Testare replay ==> set up logging for comparison\n",
        "- Check fidelity score implementation correctness\n",
        "- Spiegare comportamento oscillatorio: secondo me dato lo spazio di ricerca cosi grande, il rischio è che esca facilmente da un local minimum la funzione"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2pDqPiVFxp"
      },
      "source": [
        "for i in range(NUM_EXPERIMENTS):\n",
        "  start = [1, 0, 0, 0]\n",
        "  target = get_quantum_state(TOLERANCE, SEED, i)\n",
        "\n",
        "  print(f\"Experiment {i}\")\n",
        "\n",
        "  experiment = Experiment(start, target, TOLERANCE, TRAINING_EPISODES, STEP_SIZE, NUM_OFFLINE_UPDATES)\n",
        "  circuit_gates, terminal_state = experiment.run_experiment()\n",
        "  target_state = QuantumState(target)\n",
        "  compare_circuits(circuit_gates, terminal_state, target_state, PATH)\n",
        "  print(\"\")\n",
        "\n",
        "  sns.heatmap(experiment._agent._W)\n",
        "  plt.show()\n",
        "  print(\"\")\n",
        "  print(\"\")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "LynFoa72p99I",
        "outputId": "b3b7de86-ea59-4d01-8ddf-e8edbd427cd8"
      },
      "source": [
        "files.download(PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_65ffe74a-dae3-4b59-8605-e265d8bb47bd\", \"logs.txt\", 7889)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuNnRBpQLEpe"
      },
      "source": [
        "## Bell Target States"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HsG6MKfQ5GL"
      },
      "source": [
        "TOLERANCE = 0.15\n",
        "TRAINING_EPISODES = 100\n",
        "STEP_SIZE = 0.0001\n",
        "NUM_OFFLINE_UPDATES = 0 # WAY WORSE IF != 0"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn6FxnB9LLtB"
      },
      "source": [
        "# Bell states amplitudes\n",
        "bell_amplitudes = np.array([[1/math.sqrt(2), 0, 0, 1/math.sqrt(2)], # |00> + |11>\n",
        "                            [0, 1/math.sqrt(2), 1/math.sqrt(2), 0], # |01> + |10>\n",
        "                            [1/math.sqrt(2), 0, 0, -1/math.sqrt(2)], # |00> - |11>\n",
        "                            [0, 1/math.sqrt(2), -1/math.sqrt(2), 0]]) # |01> - |10>\n",
        "bell_dict = {\n",
        "    '|00> + |11>' : bell_amplitudes[0],\n",
        "    '|01> + |10>' : bell_amplitudes[1],\n",
        "    '|00> - |11>' : bell_amplitudes[2],\n",
        "    '|01> - |10>' : bell_amplitudes[3],\n",
        "}"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmkD7aj361y_"
      },
      "source": [
        "### Parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NKF5kmFX30K"
      },
      "source": [
        "params = {'step_size': [0.0001, 0.0005, 0.00005],\n",
        "          'negative_reward' : [-1., -3., -6. ,-10., -20.], \n",
        "          'positive_reward' : [20., 50., 80., 100., 150.]}\n",
        "param_grid = ParameterGrid(params)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmtpRnrMOqJv",
        "outputId": "db076353-7d04-44ff-982c-92477ef8aed0"
      },
      "source": [
        "%%time\n",
        "def experiment_logs(logs, circuit_gates, final_state, target_state, params, rep):\n",
        "  logs[rep]['fidelity'].append(target_state.fidelity_score(final_state))\n",
        "  logs[rep]['num_gates'].append(len(circuit_gates))\n",
        "  logs[rep]['params'].append(params)\n",
        "\n",
        "gridsearch_logs = {key:{'params': [], 'fidelity':[], 'num_gates':[]} for key in bell_dict.keys()}\n",
        "\n",
        "for params in  param_grid:\n",
        "  print(params)\n",
        "  step_size, negative_reward, positive_reward = list(params.values())\n",
        "  for rep, bell_state in bell_dict.items():\n",
        "    print(rep)\n",
        "    start = [1, 0, 0, 0]\n",
        "    target = bell_state\n",
        "\n",
        "    experiment = Experiment(start, target, TOLERANCE, TRAINING_EPISODES, STEP_SIZE, NUM_OFFLINE_UPDATES,\n",
        "                            negative_reward = -6, positive_reward = 100)\n",
        "    circuit_gates, terminal_state = experiment.run_experiment()\n",
        "\n",
        "    experiment_logs(gridsearch_logs, circuit_gates, terminal_state, QuantumState(target), params, rep)\n",
        "    print()\n",
        "  print()\n",
        "\n",
        "gridsearch_df = pd.DataFrame(gridsearch_logs)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'negative_reward': -1.0, 'positive_reward': 20.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 37: inference completed in 3 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 39: inference completed in 4 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 60: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 61: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 76: inference completed in 3 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 78: inference completed in 3 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> + |10>\n",
            "Episode 16: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|00> - |11>\n",
            "Episode 1: inference completed in 7 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 4: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 20.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 8: inference completed in 9 steps. Fidelity score: 0.933012701892219\n",
            "Episode 46: inference completed in 8 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 47: inference completed in 9 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 49: inference completed in 18 steps. Fidelity score: 0.933012701892219\n",
            "Episode 88: inference completed in 19 steps. Fidelity score: 0.8888671152155714\n",
            "Episode 89: inference completed in 16 steps. Fidelity score: 0.8600925490014673\n",
            "Episode 98: inference completed in 14 steps. Fidelity score: 0.8705127018922191\n",
            "\n",
            "|00> - |11>\n",
            "Episode 0: inference completed in 8 steps. Fidelity score: 0.933012701892219\n",
            "Episode 6: inference completed in 14 steps. Fidelity score: 0.8892777314910216\n",
            "Episode 9: inference completed in 15 steps. Fidelity score: 0.8978765877365272\n",
            "Episode 27: inference completed in 8 steps. Fidelity score: 0.853553390593274\n",
            "Episode 28: inference completed in 8 steps. Fidelity score: 0.853553390593274\n",
            "Episode 29: inference completed in 8 steps. Fidelity score: 0.853553390593274\n",
            "Episode 30: inference completed in 5 steps. Fidelity score: 0.9084708691207959\n",
            "Episode 31: inference completed in 5 steps. Fidelity score: 0.9084708691207959\n",
            "Episode 94: inference completed in 15 steps. Fidelity score: 0.8945745654962155\n",
            "\n",
            "|01> - |10>\n",
            "Episode 31: inference completed in 11 steps. Fidelity score: 0.874699408023956\n",
            "Episode 32: inference completed in 9 steps. Fidelity score: 0.9829629131445343\n",
            "Episode 50: inference completed in 16 steps. Fidelity score: 0.8932830462427467\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 20.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 75: inference completed in 16 steps. Fidelity score: 0.8746994080239555\n",
            "Episode 82: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 83: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 84: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|00> - |11>\n",
            "Episode 59: inference completed in 12 steps. Fidelity score: 0.9040063509461095\n",
            "\n",
            "|01> - |10>\n",
            "Episode 63: inference completed in 10 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 68: inference completed in 12 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 72: inference completed in 19 steps. Fidelity score: 0.8861904258006515\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 50.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 58: inference completed in 18 steps. Fidelity score: 0.8534587477519465\n",
            "Episode 59: inference completed in 19 steps. Fidelity score: 0.9164442885488363\n",
            "Episode 60: inference completed in 15 steps. Fidelity score: 0.9153215173758095\n",
            "Episode 61: inference completed in 15 steps. Fidelity score: 0.9153215173758095\n",
            "\n",
            "|00> - |11>\n",
            "Episode 11: inference completed in 18 steps. Fidelity score: 0.8695994598700576\n",
            "Episode 16: inference completed in 9 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 17: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 19: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 26: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 27: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 49: inference completed in 14 steps. Fidelity score: 0.9829629131445337\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 50.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 2: inference completed in 18 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 5: inference completed in 14 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 12: inference completed in 19 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 14: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 16: inference completed in 17 steps. Fidelity score: 0.9999999999999993\n",
            "Episode 22: inference completed in 17 steps. Fidelity score: 0.9999999999999993\n",
            "Episode 58: inference completed in 14 steps. Fidelity score: 1.0\n",
            "Episode 59: inference completed in 10 steps. Fidelity score: 0.933012701892219\n",
            "Episode 68: inference completed in 13 steps. Fidelity score: 0.9330127018922196\n",
            "\n",
            "|00> - |11>\n",
            "Episode 8: inference completed in 15 steps. Fidelity score: 0.8750000000000004\n",
            "Episode 78: inference completed in 10 steps. Fidelity score: 0.9171168834528284\n",
            "\n",
            "|01> - |10>\n",
            "Episode 37: inference completed in 19 steps. Fidelity score: 0.853553390593273\n",
            "Episode 38: inference completed in 19 steps. Fidelity score: 0.853553390593273\n",
            "Episode 96: inference completed in 18 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 98: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 99: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 50.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 70: inference completed in 18 steps. Fidelity score: 0.9153215173758099\n",
            "Episode 78: inference completed in 17 steps. Fidelity score: 0.9727076194187981\n",
            "\n",
            "|01> - |10>\n",
            "Episode 8: inference completed in 10 steps. Fidelity score: 0.8600925490014675\n",
            "Episode 16: inference completed in 14 steps. Fidelity score: 0.8705127018922186\n",
            "Episode 46: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 47: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 48: inference completed in 6 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 51: inference completed in 11 steps. Fidelity score: 0.9592793267718452\n",
            "Episode 52: inference completed in 11 steps. Fidelity score: 0.9592793267718452\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 80.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 34: inference completed in 18 steps. Fidelity score: 0.9665063509461094\n",
            "\n",
            "|01> + |10>\n",
            "Episode 50: inference completed in 15 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|00> - |11>\n",
            "Episode 7: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 55: inference completed in 15 steps. Fidelity score: 0.9469750166938905\n",
            "\n",
            "|01> - |10>\n",
            "Episode 59: inference completed in 16 steps. Fidelity score: 0.9799511532327428\n",
            "Episode 60: inference completed in 16 steps. Fidelity score: 0.9799511532327428\n",
            "Episode 64: inference completed in 16 steps. Fidelity score: 0.9510510456726331\n",
            "Episode 88: inference completed in 10 steps. Fidelity score: 0.8567465193097621\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 80.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 9: inference completed in 4 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 14: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 15: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 16: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 17: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 18: inference completed in 3 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 19: inference completed in 3 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 20: inference completed in 4 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 35: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 36: inference completed in 4 steps. Fidelity score: 0.933012701892219\n",
            "Episode 37: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 38: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 39: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 40: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 42: inference completed in 10 steps. Fidelity score: 0.933012701892219\n",
            "Episode 45: inference completed in 4 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 46: inference completed in 4 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 65: inference completed in 16 steps. Fidelity score: 0.9633883476483177\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 59: inference completed in 18 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 60: inference completed in 18 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 62: inference completed in 14 steps. Fidelity score: 0.853553390593274\n",
            "Episode 63: inference completed in 14 steps. Fidelity score: 0.853553390593274\n",
            "Episode 64: inference completed in 14 steps. Fidelity score: 0.853553390593274\n",
            "Episode 77: inference completed in 16 steps. Fidelity score: 0.8535533905932733\n",
            "\n",
            "|01> - |10>\n",
            "Episode 14: inference completed in 14 steps. Fidelity score: 0.9829629131445341\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 80.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 32: inference completed in 10 steps. Fidelity score: 0.8716345264191647\n",
            "\n",
            "|01> + |10>\n",
            "Episode 6: inference completed in 16 steps. Fidelity score: 0.9829629131445339\n",
            "Episode 10: inference completed in 14 steps. Fidelity score: 0.8646944285294568\n",
            "Episode 14: inference completed in 17 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 98: inference completed in 19 steps. Fidelity score: 0.9829629131445341\n",
            "\n",
            "|00> - |11>\n",
            "Episode 96: inference completed in 16 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 99: inference completed in 16 steps. Fidelity score: 0.8535533905932733\n",
            "\n",
            "|01> - |10>\n",
            "Episode 11: inference completed in 19 steps. Fidelity score: 0.8861377018922197\n",
            "Episode 24: inference completed in 7 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 47: inference completed in 16 steps. Fidelity score: 0.9419417382415919\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 100.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 18: inference completed in 12 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 19: inference completed in 12 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 37: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 46: inference completed in 9 steps. Fidelity score: 0.9182581518689036\n",
            "Episode 91: inference completed in 18 steps. Fidelity score: 0.8535533905932733\n",
            "\n",
            "|01> + |10>\n",
            "Episode 3: inference completed in 12 steps. Fidelity score: 0.855758151868904\n",
            "\n",
            "|00> - |11>\n",
            "Episode 28: inference completed in 16 steps. Fidelity score: 0.8945745654962153\n",
            "\n",
            "|01> - |10>\n",
            "Episode 38: inference completed in 8 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 100.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 62: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "|01> + |10>\n",
            "Episode 63: inference completed in 17 steps. Fidelity score: 0.8705127018922189\n",
            "\n",
            "|00> - |11>\n",
            "Episode 4: inference completed in 13 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 71: inference completed in 13 steps. Fidelity score: 0.853553390593274\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 100.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 9: inference completed in 16 steps. Fidelity score: 0.8688085690790632\n",
            "Episode 18: inference completed in 9 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 23: inference completed in 13 steps. Fidelity score: 0.933012701892219\n",
            "Episode 24: inference completed in 13 steps. Fidelity score: 0.933012701892219\n",
            "Episode 50: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 51: inference completed in 16 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 67: inference completed in 11 steps. Fidelity score: 0.860092549001467\n",
            "Episode 80: inference completed in 19 steps. Fidelity score: 1.0\n",
            "Episode 99: inference completed in 11 steps. Fidelity score: 0.8535533905932737\n",
            "\n",
            "|01> + |10>\n",
            "Episode 4: inference completed in 11 steps. Fidelity score: 0.9592793267718455\n",
            "Episode 5: inference completed in 17 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 8: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 23: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 24: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 13: inference completed in 17 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 34: inference completed in 16 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 55: inference completed in 9 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 62: inference completed in 16 steps. Fidelity score: 0.933012701892219\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 150.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 8: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 9: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 10: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 11: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 12: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 13: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 14: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 15: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 17: inference completed in 13 steps. Fidelity score: 0.959279326771845\n",
            "Episode 18: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 19: inference completed in 4 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 20: inference completed in 6 steps. Fidelity score: 0.933012701892219\n",
            "Episode 49: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 50: inference completed in 9 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 52: inference completed in 8 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 53: inference completed in 11 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 54: inference completed in 8 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 58: inference completed in 10 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 59: inference completed in 8 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 60: inference completed in 8 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 61: inference completed in 8 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 62: inference completed in 8 steps. Fidelity score: 0.933012701892219\n",
            "Episode 98: inference completed in 9 steps. Fidelity score: 0.874699408023956\n",
            "\n",
            "|01> + |10>\n",
            "Episode 79: inference completed in 13 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|00> - |11>\n",
            "Episode 23: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 29: inference completed in 13 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 81: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 82: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 83: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 84: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> - |10>\n",
            "Episode 23: inference completed in 7 steps. Fidelity score: 0.853553390593274\n",
            "Episode 46: inference completed in 10 steps. Fidelity score: 0.9330127018922196\n",
            "Episode 90: inference completed in 11 steps. Fidelity score: 0.9182581518689038\n",
            "Episode 91: inference completed in 11 steps. Fidelity score: 0.9182581518689038\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 150.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 18: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 63: inference completed in 4 steps. Fidelity score: 0.875\n",
            "Episode 76: inference completed in 8 steps. Fidelity score: 0.9171168834528288\n",
            "Episode 78: inference completed in 9 steps. Fidelity score: 0.9171168834528288\n",
            "\n",
            "|01> + |10>\n",
            "Episode 47: inference completed in 18 steps. Fidelity score: 0.875\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 45: inference completed in 4 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 46: inference completed in 4 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 47: inference completed in 4 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 48: inference completed in 4 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 64: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 65: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 66: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 67: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 68: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 69: inference completed in 6 steps. Fidelity score: 0.875\n",
            "Episode 70: inference completed in 6 steps. Fidelity score: 0.875\n",
            "Episode 72: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 73: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 74: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 75: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 76: inference completed in 17 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 77: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 78: inference completed in 9 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 79: inference completed in 9 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "\n",
            "{'negative_reward': -1.0, 'positive_reward': 150.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 45: inference completed in 9 steps. Fidelity score: 0.9829629131445339\n",
            "Episode 71: inference completed in 12 steps. Fidelity score: 0.9592793267718457\n",
            "Episode 72: inference completed in 19 steps. Fidelity score: 0.8705127018922186\n",
            "Episode 73: inference completed in 19 steps. Fidelity score: 0.8705127018922186\n",
            "Episode 74: inference completed in 7 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "Episode 92: inference completed in 16 steps. Fidelity score: 0.9829629131445343\n",
            "Episode 94: inference completed in 19 steps. Fidelity score: 0.908796107873473\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 55: inference completed in 8 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 83: inference completed in 19 steps. Fidelity score: 0.8922074189910213\n",
            "Episode 93: inference completed in 6 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 94: inference completed in 18 steps. Fidelity score: 0.857421875\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 20.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 13: inference completed in 10 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 32: inference completed in 10 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 33: inference completed in 10 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 34: inference completed in 10 steps. Fidelity score: 0.8749999999999996\n",
            "Episode 42: inference completed in 15 steps. Fidelity score: 0.8895625846230001\n",
            "Episode 92: inference completed in 19 steps. Fidelity score: 0.8843861423693368\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 36: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 51: inference completed in 16 steps. Fidelity score: 0.9171168834528284\n",
            "Episode 63: inference completed in 15 steps. Fidelity score: 1.0\n",
            "Episode 64: inference completed in 15 steps. Fidelity score: 1.0\n",
            "Episode 67: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 20.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 27: inference completed in 16 steps. Fidelity score: 0.8718391103455287\n",
            "Episode 28: inference completed in 12 steps. Fidelity score: 0.861215249146588\n",
            "Episode 71: inference completed in 17 steps. Fidelity score: 0.8756257041613341\n",
            "Episode 73: inference completed in 19 steps. Fidelity score: 0.8866701108564525\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 3: inference completed in 8 steps. Fidelity score: 0.875\n",
            "Episode 70: inference completed in 17 steps. Fidelity score: 0.853553390593274\n",
            "Episode 71: inference completed in 17 steps. Fidelity score: 0.853553390593274\n",
            "\n",
            "|01> - |10>\n",
            "Episode 4: inference completed in 7 steps. Fidelity score: 0.9040063509461094\n",
            "Episode 5: inference completed in 7 steps. Fidelity score: 0.9040063509461094\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 20.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 33: inference completed in 11 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 34: inference completed in 11 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 35: inference completed in 18 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 37: inference completed in 15 steps. Fidelity score: 0.9999999999999991\n",
            "Episode 38: inference completed in 15 steps. Fidelity score: 0.9999999999999991\n",
            "Episode 42: inference completed in 12 steps. Fidelity score: 1.0\n",
            "Episode 43: inference completed in 12 steps. Fidelity score: 1.0\n",
            "Episode 61: inference completed in 10 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 62: inference completed in 11 steps. Fidelity score: 0.9829629131445343\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 35: inference completed in 13 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 76: inference completed in 12 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 84: inference completed in 16 steps. Fidelity score: 0.8620320476006286\n",
            "Episode 85: inference completed in 16 steps. Fidelity score: 0.8620320476006286\n",
            "Episode 88: inference completed in 16 steps. Fidelity score: 0.8620320476006286\n",
            "Episode 96: inference completed in 9 steps. Fidelity score: 0.9999999999999996\n",
            "\n",
            "|01> - |10>\n",
            "Episode 13: inference completed in 8 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 14: inference completed in 8 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 50.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 39: inference completed in 14 steps. Fidelity score: 0.9330127018922196\n",
            "Episode 43: inference completed in 14 steps. Fidelity score: 0.9330127018922196\n",
            "Episode 47: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 48: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 49: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 50: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 52: inference completed in 15 steps. Fidelity score: 0.8861377018922193\n",
            "Episode 87: inference completed in 10 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 88: inference completed in 10 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 89: inference completed in 10 steps. Fidelity score: 0.8750000000000002\n",
            "\n",
            "|01> + |10>\n",
            "Episode 1: inference completed in 16 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 95: inference completed in 9 steps. Fidelity score: 0.933012701892219\n",
            "Episode 96: inference completed in 9 steps. Fidelity score: 0.933012701892219\n",
            "Episode 97: inference completed in 9 steps. Fidelity score: 0.9742941188794071\n",
            "\n",
            "|00> - |11>\n",
            "Episode 22: inference completed in 14 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 23: inference completed in 18 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 50.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 11: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 12: inference completed in 9 steps. Fidelity score: 0.853553390593274\n",
            "Episode 13: inference completed in 7 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 14: inference completed in 8 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 15: inference completed in 6 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "|01> - |10>\n",
            "Episode 90: inference completed in 15 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 50.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 4: inference completed in 12 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 9: inference completed in 18 steps. Fidelity score: 0.9040063509461095\n",
            "Episode 11: inference completed in 3 steps. Fidelity score: 0.933012701892219\n",
            "Episode 12: inference completed in 3 steps. Fidelity score: 0.933012701892219\n",
            "Episode 13: inference completed in 3 steps. Fidelity score: 0.933012701892219\n",
            "Episode 14: inference completed in 3 steps. Fidelity score: 0.933012701892219\n",
            "Episode 15: inference completed in 3 steps. Fidelity score: 0.933012701892219\n",
            "Episode 16: inference completed in 3 steps. Fidelity score: 0.933012701892219\n",
            "Episode 17: inference completed in 3 steps. Fidelity score: 0.933012701892219\n",
            "Episode 18: inference completed in 5 steps. Fidelity score: 0.869599459870058\n",
            "\n",
            "|01> + |10>\n",
            "Episode 27: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 28: inference completed in 7 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 37: inference completed in 8 steps. Fidelity score: 0.9999999999999993\n",
            "Episode 63: inference completed in 9 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 80: inference completed in 13 steps. Fidelity score: 0.8705127018922195\n",
            "\n",
            "|00> - |11>\n",
            "Episode 35: inference completed in 17 steps. Fidelity score: 0.8978555468533218\n",
            "Episode 36: inference completed in 17 steps. Fidelity score: 0.8978555468533218\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 80.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 71: inference completed in 15 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 73: inference completed in 15 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|01> + |10>\n",
            "Episode 88: inference completed in 18 steps. Fidelity score: 0.96875\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 13: inference completed in 19 steps. Fidelity score: 0.9171168834528279\n",
            "Episode 56: inference completed in 15 steps. Fidelity score: 0.9019148266600386\n",
            "Episode 74: inference completed in 10 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 76: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 80.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 46: inference completed in 15 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 47: inference completed in 15 steps. Fidelity score: 0.9171168834528286\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 5: inference completed in 15 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 80.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 9: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 10: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 13: inference completed in 10 steps. Fidelity score: 1.0\n",
            "Episode 14: inference completed in 10 steps. Fidelity score: 1.0\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 47: inference completed in 15 steps. Fidelity score: 0.8850987725949278\n",
            "Episode 76: inference completed in 19 steps. Fidelity score: 0.8875023355893324\n",
            "Episode 82: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 83: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|01> - |10>\n",
            "Episode 31: inference completed in 14 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 58: inference completed in 8 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 70: inference completed in 14 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 100.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 42: inference completed in 17 steps. Fidelity score: 0.9040063509461095\n",
            "Episode 96: inference completed in 8 steps. Fidelity score: 0.8705127018922191\n",
            "\n",
            "|01> + |10>\n",
            "Episode 2: inference completed in 7 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 55: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 56: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 57: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 60: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 61: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 62: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|00> - |11>\n",
            "Episode 13: inference completed in 15 steps. Fidelity score: 0.9497595264191646\n",
            "Episode 14: inference completed in 7 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 20: inference completed in 9 steps. Fidelity score: 0.9374999999999999\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 100.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 6: inference completed in 10 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 24: inference completed in 14 steps. Fidelity score: 0.9330127018922187\n",
            "Episode 65: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 80: inference completed in 10 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 82: inference completed in 12 steps. Fidelity score: 0.9182581518689038\n",
            "Episode 91: inference completed in 18 steps. Fidelity score: 0.9182581518689034\n",
            "\n",
            "|01> + |10>\n",
            "Episode 4: inference completed in 17 steps. Fidelity score: 0.8746994080239562\n",
            "Episode 15: inference completed in 10 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 25: inference completed in 14 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 30: inference completed in 12 steps. Fidelity score: 0.875\n",
            "Episode 33: inference completed in 10 steps. Fidelity score: 0.875\n",
            "\n",
            "|00> - |11>\n",
            "Episode 41: inference completed in 19 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 59: inference completed in 11 steps. Fidelity score: 0.933012701892219\n",
            "\n",
            "|01> - |10>\n",
            "Episode 19: inference completed in 19 steps. Fidelity score: 0.8863403451375659\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 100.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 9: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 10: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 11: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 24: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 38: inference completed in 14 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 75: inference completed in 6 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 77: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 80: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 81: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 82: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 83: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 84: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 90: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "Episode 72: inference completed in 16 steps. Fidelity score: 0.8697671436215297\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 56: inference completed in 15 steps. Fidelity score: 0.8665177393633319\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 150.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 25: inference completed in 15 steps. Fidelity score: 0.8717848224071872\n",
            "Episode 31: inference completed in 11 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|00> - |11>\n",
            "Episode 11: inference completed in 18 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 13: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 15: inference completed in 19 steps. Fidelity score: 0.9374999999999994\n",
            "Episode 55: inference completed in 19 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 65: inference completed in 8 steps. Fidelity score: 0.875\n",
            "\n",
            "|01> - |10>\n",
            "Episode 84: inference completed in 19 steps. Fidelity score: 0.853553390593274\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 150.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 33: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 34: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 42: inference completed in 11 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 50: inference completed in 16 steps. Fidelity score: 0.9832531754730542\n",
            "Episode 51: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 58: inference completed in 7 steps. Fidelity score: 0.933012701892219\n",
            "Episode 59: inference completed in 7 steps. Fidelity score: 0.933012701892219\n",
            "Episode 60: inference completed in 9 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 90: inference completed in 14 steps. Fidelity score: 0.8749999999999998\n",
            "\n",
            "|01> + |10>\n",
            "Episode 12: inference completed in 10 steps. Fidelity score: 0.8719382367741585\n",
            "\n",
            "|00> - |11>\n",
            "Episode 61: inference completed in 18 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -3.0, 'positive_reward': 150.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 14: inference completed in 9 steps. Fidelity score: 0.875\n",
            "Episode 25: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 26: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 27: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 28: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "\n",
            "|01> + |10>\n",
            "Episode 6: inference completed in 18 steps. Fidelity score: 0.895019796540749\n",
            "\n",
            "|00> - |11>\n",
            "Episode 70: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 71: inference completed in 19 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 76: inference completed in 11 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 83: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 89: inference completed in 16 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 93: inference completed in 16 steps. Fidelity score: 0.9330127018922187\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 20.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 32: inference completed in 11 steps. Fidelity score: 0.8749999999999998\n",
            "\n",
            "|00> - |11>\n",
            "Episode 25: inference completed in 7 steps. Fidelity score: 0.875\n",
            "Episode 27: inference completed in 7 steps. Fidelity score: 0.875\n",
            "Episode 35: inference completed in 16 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> - |10>\n",
            "Episode 0: inference completed in 12 steps. Fidelity score: 0.8750000000000002\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 20.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 44: inference completed in 19 steps. Fidelity score: 0.9330127018922199\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 20.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 68: inference completed in 16 steps. Fidelity score: 0.9375000000000003\n",
            "Episode 83: inference completed in 15 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 87: inference completed in 9 steps. Fidelity score: 1.0\n",
            "\n",
            "|01> - |10>\n",
            "Episode 38: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 50.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 47: inference completed in 14 steps. Fidelity score: 0.8557581518689038\n",
            "\n",
            "|01> + |10>\n",
            "Episode 94: inference completed in 10 steps. Fidelity score: 0.933012701892219\n",
            "Episode 97: inference completed in 17 steps. Fidelity score: 0.8565138388898599\n",
            "\n",
            "|00> - |11>\n",
            "Episode 5: inference completed in 13 steps. Fidelity score: 0.8750000000000002\n",
            "\n",
            "|01> - |10>\n",
            "Episode 10: inference completed in 12 steps. Fidelity score: 0.9173877018922197\n",
            "Episode 12: inference completed in 19 steps. Fidelity score: 0.933012701892219\n",
            "Episode 14: inference completed in 18 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 51: inference completed in 18 steps. Fidelity score: 0.9171168834528282\n",
            "Episode 52: inference completed in 18 steps. Fidelity score: 0.9171168834528282\n",
            "Episode 73: inference completed in 13 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 50.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 36: inference completed in 10 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 37: inference completed in 10 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 66: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 79: inference completed in 13 steps. Fidelity score: 0.9829629131445339\n",
            "\n",
            "|01> + |10>\n",
            "Episode 1: inference completed in 12 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 6: inference completed in 10 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 7: inference completed in 5 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 68: inference completed in 12 steps. Fidelity score: 0.8847872827481077\n",
            "Episode 75: inference completed in 19 steps. Fidelity score: 0.8832887941803389\n",
            "Episode 98: inference completed in 18 steps. Fidelity score: 0.875\n",
            "Episode 99: inference completed in 14 steps. Fidelity score: 0.8750000000000004\n",
            "\n",
            "|00> - |11>\n",
            "Episode 77: inference completed in 18 steps. Fidelity score: 0.9832531754730551\n",
            "Episode 94: inference completed in 17 steps. Fidelity score: 0.8788436062218418\n",
            "\n",
            "|01> - |10>\n",
            "Episode 40: inference completed in 13 steps. Fidelity score: 0.875\n",
            "Episode 41: inference completed in 13 steps. Fidelity score: 0.875\n",
            "Episode 53: inference completed in 10 steps. Fidelity score: 0.9330127018922196\n",
            "Episode 79: inference completed in 8 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 84: inference completed in 8 steps. Fidelity score: 0.875\n",
            "Episode 85: inference completed in 8 steps. Fidelity score: 0.875\n",
            "Episode 87: inference completed in 8 steps. Fidelity score: 0.875\n",
            "Episode 88: inference completed in 8 steps. Fidelity score: 0.875\n",
            "Episode 89: inference completed in 8 steps. Fidelity score: 0.875\n",
            "Episode 90: inference completed in 8 steps. Fidelity score: 0.875\n",
            "Episode 91: inference completed in 9 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 92: inference completed in 9 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 93: inference completed in 9 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 50.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 12: inference completed in 8 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 18: inference completed in 9 steps. Fidelity score: 1.0\n",
            "Episode 19: inference completed in 9 steps. Fidelity score: 1.0\n",
            "Episode 20: inference completed in 9 steps. Fidelity score: 1.0\n",
            "Episode 21: inference completed in 9 steps. Fidelity score: 1.0\n",
            "Episode 23: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 28: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 29: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 32: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|01> + |10>\n",
            "Episode 19: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 20: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 21: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 57: inference completed in 5 steps. Fidelity score: 0.933012701892219\n",
            "Episode 59: inference completed in 5 steps. Fidelity score: 0.933012701892219\n",
            "Episode 66: inference completed in 5 steps. Fidelity score: 0.933012701892219\n",
            "Episode 68: inference completed in 5 steps. Fidelity score: 0.933012701892219\n",
            "Episode 71: inference completed in 5 steps. Fidelity score: 0.933012701892219\n",
            "\n",
            "|00> - |11>\n",
            "Episode 17: inference completed in 11 steps. Fidelity score: 0.8988535652108383\n",
            "Episode 34: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 35: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 55: inference completed in 16 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 56: inference completed in 16 steps. Fidelity score: 0.8705127018922191\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 80.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 8: inference completed in 10 steps. Fidelity score: 0.853553390593274\n",
            "\n",
            "|01> + |10>\n",
            "Episode 26: inference completed in 6 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 27: inference completed in 13 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 28: inference completed in 6 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 29: inference completed in 17 steps. Fidelity score: 0.853553390593273\n",
            "Episode 31: inference completed in 6 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 32: inference completed in 6 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 33: inference completed in 6 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 35: inference completed in 9 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 37: inference completed in 10 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 38: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 40: inference completed in 13 steps. Fidelity score: 0.8600925490014673\n",
            "Episode 42: inference completed in 9 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 45: inference completed in 11 steps. Fidelity score: 1.0\n",
            "\n",
            "|00> - |11>\n",
            "Episode 15: inference completed in 16 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 44: inference completed in 17 steps. Fidelity score: 0.875\n",
            "Episode 47: inference completed in 18 steps. Fidelity score: 0.9425493862974638\n",
            "Episode 90: inference completed in 15 steps. Fidelity score: 0.8861377018922195\n",
            "Episode 93: inference completed in 16 steps. Fidelity score: 0.9829629131445341\n",
            "\n",
            "|01> - |10>\n",
            "Episode 50: inference completed in 19 steps. Fidelity score: 0.869599459870058\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 80.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 14: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|00> - |11>\n",
            "Episode 37: inference completed in 14 steps. Fidelity score: 0.8705127018922195\n",
            "\n",
            "|01> - |10>\n",
            "Episode 23: inference completed in 13 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 24: inference completed in 13 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 61: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 63: inference completed in 14 steps. Fidelity score: 0.9999999999999993\n",
            "Episode 66: inference completed in 9 steps. Fidelity score: 0.8788436062218417\n",
            "Episode 67: inference completed in 18 steps. Fidelity score: 0.911746427419792\n",
            "Episode 68: inference completed in 18 steps. Fidelity score: 0.911746427419792\n",
            "Episode 71: inference completed in 13 steps. Fidelity score: 0.8612260476065856\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 80.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 4: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 5: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 10: inference completed in 11 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 47: inference completed in 11 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 54: inference completed in 11 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 55: inference completed in 11 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 56: inference completed in 11 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 59: inference completed in 9 steps. Fidelity score: 0.853553390593274\n",
            "Episode 65: inference completed in 10 steps. Fidelity score: 0.9040063509461097\n",
            "Episode 74: inference completed in 10 steps. Fidelity score: 0.9040063509461097\n",
            "Episode 75: inference completed in 9 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 79: inference completed in 9 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 80: inference completed in 9 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 81: inference completed in 9 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 84: inference completed in 13 steps. Fidelity score: 0.9335783908757554\n",
            "\n",
            "|01> + |10>\n",
            "Episode 91: inference completed in 13 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 94: inference completed in 14 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 98: inference completed in 18 steps. Fidelity score: 0.8512619080239554\n",
            "Episode 99: inference completed in 18 steps. Fidelity score: 0.8512619080239554\n",
            "\n",
            "|00> - |11>\n",
            "Episode 60: inference completed in 15 steps. Fidelity score: 0.8768579557128066\n",
            "Episode 82: inference completed in 17 steps. Fidelity score: 0.9269269461340306\n",
            "\n",
            "|01> - |10>\n",
            "Episode 15: inference completed in 10 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 18: inference completed in 10 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 79: inference completed in 19 steps. Fidelity score: 0.9592793267718457\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 100.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 8: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 9: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 11: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "Episode 69: inference completed in 13 steps. Fidelity score: 0.8705127018922195\n",
            "\n",
            "|00> - |11>\n",
            "Episode 33: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 34: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 37: inference completed in 14 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 38: inference completed in 14 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 56: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 57: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 66: inference completed in 4 steps. Fidelity score: 0.875\n",
            "Episode 79: inference completed in 15 steps. Fidelity score: 0.8567465193097619\n",
            "Episode 94: inference completed in 17 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 95: inference completed in 19 steps. Fidelity score: 0.8746994080239555\n",
            "Episode 97: inference completed in 17 steps. Fidelity score: 0.8705127018922195\n",
            "\n",
            "|01> - |10>\n",
            "Episode 4: inference completed in 14 steps. Fidelity score: 0.9330127018922187\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 100.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 20: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 62: inference completed in 10 steps. Fidelity score: 0.8695994598700583\n",
            "Episode 63: inference completed in 11 steps. Fidelity score: 0.869599459870058\n",
            "Episode 67: inference completed in 11 steps. Fidelity score: 0.869599459870058\n",
            "Episode 68: inference completed in 11 steps. Fidelity score: 0.869599459870058\n",
            "Episode 69: inference completed in 11 steps. Fidelity score: 0.869599459870058\n",
            "Episode 70: inference completed in 11 steps. Fidelity score: 0.869599459870058\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 3: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 20: inference completed in 19 steps. Fidelity score: 0.9104722568600339\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 100.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 69: inference completed in 8 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 70: inference completed in 7 steps. Fidelity score: 0.853553390593274\n",
            "Episode 71: inference completed in 7 steps. Fidelity score: 0.853553390593274\n",
            "Episode 75: inference completed in 14 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 78: inference completed in 16 steps. Fidelity score: 1.0\n",
            "Episode 79: inference completed in 16 steps. Fidelity score: 1.0\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 36: inference completed in 19 steps. Fidelity score: 0.8705127018922186\n",
            "Episode 90: inference completed in 9 steps. Fidelity score: 0.9330127018922199\n",
            "\n",
            "|01> - |10>\n",
            "Episode 2: inference completed in 9 steps. Fidelity score: 0.895019796540749\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 150.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 5: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 7: inference completed in 7 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 11: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 46: inference completed in 19 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 53: inference completed in 18 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 90: inference completed in 11 steps. Fidelity score: 0.875\n",
            "Episode 91: inference completed in 10 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 92: inference completed in 10 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 94: inference completed in 14 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 95: inference completed in 12 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|01> + |10>\n",
            "Episode 16: inference completed in 19 steps. Fidelity score: 0.9021050123704034\n",
            "Episode 24: inference completed in 15 steps. Fidelity score: 0.9171168834528279\n",
            "Episode 26: inference completed in 14 steps. Fidelity score: 0.933012701892219\n",
            "Episode 34: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 35: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 36: inference completed in 13 steps. Fidelity score: 0.9040063509461095\n",
            "Episode 38: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 64: inference completed in 16 steps. Fidelity score: 0.9171168834528284\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 0: inference completed in 16 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 5: inference completed in 12 steps. Fidelity score: 0.9341345264191642\n",
            "Episode 8: inference completed in 5 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 31: inference completed in 12 steps. Fidelity score: 0.8535533905932737\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 150.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 63: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 64: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 65: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 66: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 68: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 69: inference completed in 11 steps. Fidelity score: 0.933012701892219\n",
            "Episode 70: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 71: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 79: inference completed in 11 steps. Fidelity score: 0.933012701892219\n",
            "Episode 86: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 96: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "Episode 33: inference completed in 17 steps. Fidelity score: 0.8780641053973939\n",
            "Episode 36: inference completed in 19 steps. Fidelity score: 0.8932830462427462\n",
            "Episode 50: inference completed in 16 steps. Fidelity score: 0.9829629131445334\n",
            "Episode 57: inference completed in 3 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 58: inference completed in 3 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 59: inference completed in 3 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 60: inference completed in 3 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 61: inference completed in 3 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 62: inference completed in 3 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 73: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 74: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 75: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 77: inference completed in 17 steps. Fidelity score: 0.9419417382415919\n",
            "Episode 97: inference completed in 17 steps. Fidelity score: 0.9040063509461094\n",
            "\n",
            "|00> - |11>\n",
            "Episode 19: inference completed in 17 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 83: inference completed in 15 steps. Fidelity score: 0.895923174562532\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -6.0, 'positive_reward': 150.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 33: inference completed in 15 steps. Fidelity score: 0.875\n",
            "Episode 89: inference completed in 17 steps. Fidelity score: 0.8988535652108378\n",
            "\n",
            "|01> + |10>\n",
            "Episode 6: inference completed in 11 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 8: inference completed in 9 steps. Fidelity score: 1.0\n",
            "Episode 17: inference completed in 15 steps. Fidelity score: 0.8968354699386112\n",
            "Episode 92: inference completed in 19 steps. Fidelity score: 0.9330127018922187\n",
            "\n",
            "|00> - |11>\n",
            "Episode 1: inference completed in 5 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> - |10>\n",
            "Episode 2: inference completed in 12 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 34: inference completed in 19 steps. Fidelity score: 0.9171168834528289\n",
            "Episode 49: inference completed in 18 steps. Fidelity score: 0.8791513151552558\n",
            "Episode 50: inference completed in 18 steps. Fidelity score: 0.8791513151552558\n",
            "Episode 51: inference completed in 16 steps. Fidelity score: 0.9197716789416812\n",
            "Episode 55: inference completed in 18 steps. Fidelity score: 0.8681350691361738\n",
            "Episode 56: inference completed in 18 steps. Fidelity score: 0.8681350691361738\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 20.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 95: inference completed in 3 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 96: inference completed in 9 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 79: inference completed in 16 steps. Fidelity score: 0.8677950627658017\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 20.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 74: inference completed in 7 steps. Fidelity score: 0.9999999999999993\n",
            "Episode 99: inference completed in 14 steps. Fidelity score: 0.8677950627658018\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 59: inference completed in 18 steps. Fidelity score: 0.860346528538923\n",
            "Episode 74: inference completed in 9 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 90: inference completed in 10 steps. Fidelity score: 0.9182581518689038\n",
            "\n",
            "|01> - |10>\n",
            "Episode 13: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 45: inference completed in 11 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 49: inference completed in 11 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 50: inference completed in 11 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 81: inference completed in 15 steps. Fidelity score: 0.9999999999999993\n",
            "Episode 88: inference completed in 10 steps. Fidelity score: 0.9999999999999993\n",
            "Episode 91: inference completed in 10 steps. Fidelity score: 0.9999999999999991\n",
            "Episode 93: inference completed in 10 steps. Fidelity score: 0.9999999999999991\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 20.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 9: inference completed in 13 steps. Fidelity score: 0.8600925490014669\n",
            "Episode 19: inference completed in 16 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 32: inference completed in 13 steps. Fidelity score: 0.8749999999999998\n",
            "\n",
            "|01> + |10>\n",
            "Episode 31: inference completed in 6 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "|00> - |11>\n",
            "Episode 22: inference completed in 6 steps. Fidelity score: 1.0\n",
            "Episode 84: inference completed in 19 steps. Fidelity score: 1.0\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 50.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 21: inference completed in 19 steps. Fidelity score: 0.9254430840269497\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 1: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 20: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 55: inference completed in 13 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 59: inference completed in 19 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 66: inference completed in 6 steps. Fidelity score: 0.9330127018922187\n",
            "Episode 68: inference completed in 9 steps. Fidelity score: 0.9330127018922187\n",
            "Episode 71: inference completed in 16 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 73: inference completed in 9 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 74: inference completed in 9 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 75: inference completed in 11 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 76: inference completed in 11 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 77: inference completed in 11 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 78: inference completed in 11 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 79: inference completed in 11 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 80: inference completed in 9 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 85: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 86: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 87: inference completed in 9 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 93: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 94: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 95: inference completed in 19 steps. Fidelity score: 0.9341345264191637\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 50.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 28: inference completed in 3 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 29: inference completed in 18 steps. Fidelity score: 0.882817560831689\n",
            "Episode 30: inference completed in 2 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 36: inference completed in 2 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 38: inference completed in 2 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 39: inference completed in 2 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 42: inference completed in 2 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 80: inference completed in 11 steps. Fidelity score: 0.9469750166938903\n",
            "\n",
            "|01> + |10>\n",
            "Episode 21: inference completed in 19 steps. Fidelity score: 0.9113411180239167\n",
            "Episode 22: inference completed in 10 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 31: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 61: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 74: inference completed in 8 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 79: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 80: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 81: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "\n",
            "|00> - |11>\n",
            "Episode 2: inference completed in 8 steps. Fidelity score: 0.9829629131445339\n",
            "Episode 31: inference completed in 6 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 32: inference completed in 7 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 64: inference completed in 10 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 81: inference completed in 17 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 94: inference completed in 15 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|01> - |10>\n",
            "Episode 34: inference completed in 11 steps. Fidelity score: 0.8535533905932737\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 50.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 3: inference completed in 4 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 16: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 17: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 18: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 19: inference completed in 5 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 20: inference completed in 6 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 25: inference completed in 19 steps. Fidelity score: 0.9140162492164834\n",
            "Episode 27: inference completed in 10 steps. Fidelity score: 0.875\n",
            "Episode 52: inference completed in 12 steps. Fidelity score: 0.9040063509461097\n",
            "Episode 53: inference completed in 9 steps. Fidelity score: 0.9040063509461095\n",
            "Episode 58: inference completed in 8 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 65: inference completed in 8 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 66: inference completed in 11 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "|01> + |10>\n",
            "Episode 2: inference completed in 12 steps. Fidelity score: 0.8554486141556918\n",
            "Episode 35: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 39: inference completed in 15 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 58: inference completed in 17 steps. Fidelity score: 0.8567465193097614\n",
            "Episode 87: inference completed in 11 steps. Fidelity score: 0.9182581518689038\n",
            "Episode 96: inference completed in 9 steps. Fidelity score: 0.9182581518689042\n",
            "Episode 97: inference completed in 11 steps. Fidelity score: 0.9171168834528284\n",
            "\n",
            "|00> - |11>\n",
            "Episode 60: inference completed in 15 steps. Fidelity score: 0.9152943488263511\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 80.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 25: inference completed in 16 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 26: inference completed in 16 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 43: inference completed in 3 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 42: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> - |10>\n",
            "Episode 40: inference completed in 12 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 41: inference completed in 9 steps. Fidelity score: 0.8705127018922195\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 80.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 90: inference completed in 8 steps. Fidelity score: 0.9948047063308786\n",
            "Episode 91: inference completed in 8 steps. Fidelity score: 0.9948047063308786\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 80.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 48: inference completed in 8 steps. Fidelity score: 0.875\n",
            "\n",
            "|01> + |10>\n",
            "Episode 29: inference completed in 4 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 71: inference completed in 13 steps. Fidelity score: 0.8749999999999996\n",
            "Episode 72: inference completed in 13 steps. Fidelity score: 0.8749999999999996\n",
            "Episode 83: inference completed in 4 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 14: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 15: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 16: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 17: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 18: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 25: inference completed in 11 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 26: inference completed in 11 steps. Fidelity score: 0.9171168834528286\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 100.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 9: inference completed in 11 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 36: inference completed in 14 steps. Fidelity score: 0.9173009023953492\n",
            "Episode 43: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 44: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 45: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 80: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 85: inference completed in 6 steps. Fidelity score: 0.875\n",
            "Episode 87: inference completed in 6 steps. Fidelity score: 0.875\n",
            "Episode 94: inference completed in 16 steps. Fidelity score: 0.9080553173017123\n",
            "\n",
            "|00> - |11>\n",
            "Episode 78: inference completed in 13 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 96: inference completed in 15 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 100.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 41: inference completed in 3 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 64: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 69: inference completed in 3 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 70: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 71: inference completed in 3 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 72: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 73: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 78: inference completed in 12 steps. Fidelity score: 0.9807581518689038\n",
            "Episode 79: inference completed in 12 steps. Fidelity score: 0.9807581518689038\n",
            "Episode 90: inference completed in 10 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 91: inference completed in 10 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 92: inference completed in 10 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 93: inference completed in 10 steps. Fidelity score: 0.8535533905932737\n",
            "\n",
            "|01> + |10>\n",
            "Episode 18: inference completed in 13 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 20: inference completed in 13 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 31: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|00> - |11>\n",
            "Episode 13: inference completed in 17 steps. Fidelity score: 0.9320994598700575\n",
            "Episode 18: inference completed in 18 steps. Fidelity score: 0.9330127018922183\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 100.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 28: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 29: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 31: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 38: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 39: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 41: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 48: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 50: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> + |10>\n",
            "Episode 45: inference completed in 18 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 53: inference completed in 9 steps. Fidelity score: 0.8945745654962155\n",
            "Episode 72: inference completed in 13 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 90: inference completed in 18 steps. Fidelity score: 0.8861377018922193\n",
            "Episode 91: inference completed in 9 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 92: inference completed in 9 steps. Fidelity score: 0.8535533905932733\n",
            "\n",
            "|00> - |11>\n",
            "Episode 24: inference completed in 15 steps. Fidelity score: 0.96875\n",
            "\n",
            "|01> - |10>\n",
            "Episode 29: inference completed in 18 steps. Fidelity score: 0.9330127018922196\n",
            "Episode 62: inference completed in 14 steps. Fidelity score: 0.875\n",
            "Episode 63: inference completed in 14 steps. Fidelity score: 0.875\n",
            "Episode 76: inference completed in 17 steps. Fidelity score: 0.9164897537739537\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 150.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 33: inference completed in 12 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 60: inference completed in 19 steps. Fidelity score: 0.8705127018922197\n",
            "Episode 61: inference completed in 19 steps. Fidelity score: 0.8705127018922197\n",
            "Episode 85: inference completed in 7 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 86: inference completed in 7 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 150.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 48: inference completed in 8 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 49: inference completed in 6 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 50: inference completed in 6 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 60: inference completed in 10 steps. Fidelity score: 0.8604579367486846\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 48: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 50: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 66: inference completed in 7 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 73: inference completed in 15 steps. Fidelity score: 0.9252203377365275\n",
            "\n",
            "|01> - |10>\n",
            "Episode 97: inference completed in 14 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "\n",
            "{'negative_reward': -10.0, 'positive_reward': 150.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 88: inference completed in 5 steps. Fidelity score: 0.9040063509461095\n",
            "Episode 90: inference completed in 8 steps. Fidelity score: 0.9727076194187986\n",
            "\n",
            "|01> + |10>\n",
            "Episode 6: inference completed in 16 steps. Fidelity score: 0.8705127018922195\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 20.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 0: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 82: inference completed in 18 steps. Fidelity score: 0.8749999999999998\n",
            "\n",
            "|01> + |10>\n",
            "Episode 25: inference completed in 8 steps. Fidelity score: 0.9419417382415921\n",
            "\n",
            "|00> - |11>\n",
            "Episode 73: inference completed in 12 steps. Fidelity score: 0.8573446513295125\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 20.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 12: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 14: inference completed in 2 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 51: inference completed in 9 steps. Fidelity score: 0.8936891053973934\n",
            "Episode 54: inference completed in 14 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 55: inference completed in 14 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 76: inference completed in 14 steps. Fidelity score: 0.9173877018922191\n",
            "Episode 93: inference completed in 13 steps. Fidelity score: 0.8715593784251534\n",
            "Episode 97: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> + |10>\n",
            "Episode 11: inference completed in 9 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 14: inference completed in 15 steps. Fidelity score: 0.9171168834528282\n",
            "Episode 59: inference completed in 8 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 62: inference completed in 7 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 63: inference completed in 7 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 90: inference completed in 12 steps. Fidelity score: 0.853553390593274\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 2: inference completed in 10 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 40: inference completed in 17 steps. Fidelity score: 0.8720405419616533\n",
            "Episode 41: inference completed in 17 steps. Fidelity score: 0.8720405419616533\n",
            "Episode 46: inference completed in 7 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 52: inference completed in 7 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 53: inference completed in 7 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 61: inference completed in 10 steps. Fidelity score: 0.8909056559911429\n",
            "Episode 63: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 86: inference completed in 15 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 88: inference completed in 10 steps. Fidelity score: 0.9330127018922187\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 20.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 14: inference completed in 9 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 17: inference completed in 10 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 18: inference completed in 10 steps. Fidelity score: 0.9999999999999996\n",
            "\n",
            "|01> + |10>\n",
            "Episode 29: inference completed in 8 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 42: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 47: inference completed in 12 steps. Fidelity score: 0.9040063509461094\n",
            "Episode 74: inference completed in 4 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 84: inference completed in 4 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 85: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 86: inference completed in 4 steps. Fidelity score: 0.8535533905932737\n",
            "\n",
            "|00> - |11>\n",
            "Episode 11: inference completed in 17 steps. Fidelity score: 0.8788436062218408\n",
            "\n",
            "|01> - |10>\n",
            "Episode 14: inference completed in 19 steps. Fidelity score: 0.8716345264191641\n",
            "Episode 15: inference completed in 10 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 16: inference completed in 10 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 19: inference completed in 12 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 60: inference completed in 11 steps. Fidelity score: 0.9151589396066557\n",
            "Episode 61: inference completed in 11 steps. Fidelity score: 0.9151589396066557\n",
            "Episode 89: inference completed in 16 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 50.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 13: inference completed in 6 steps. Fidelity score: 1.0\n",
            "Episode 14: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 15: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 16: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 17: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 18: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 19: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 20: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 21: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 22: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 23: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 24: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 25: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 26: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 27: inference completed in 5 steps. Fidelity score: 1.0\n",
            "Episode 28: inference completed in 5 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 30: inference completed in 16 steps. Fidelity score: 0.8749999999999996\n",
            "Episode 35: inference completed in 17 steps. Fidelity score: 0.875\n",
            "Episode 36: inference completed in 15 steps. Fidelity score: 0.9182581518689036\n",
            "Episode 90: inference completed in 6 steps. Fidelity score: 0.9330127018922196\n",
            "Episode 91: inference completed in 6 steps. Fidelity score: 0.9330127018922196\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 31: inference completed in 17 steps. Fidelity score: 0.8659108223642296\n",
            "Episode 34: inference completed in 14 steps. Fidelity score: 0.9387687393203746\n",
            "Episode 46: inference completed in 14 steps. Fidelity score: 0.9383096596552278\n",
            "Episode 49: inference completed in 19 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 63: inference completed in 8 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 64: inference completed in 14 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 69: inference completed in 8 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 71: inference completed in 8 steps. Fidelity score: 0.8535533905932731\n",
            "Episode 75: inference completed in 5 steps. Fidelity score: 0.9182581518689042\n",
            "Episode 77: inference completed in 6 steps. Fidelity score: 0.9592793267718457\n",
            "Episode 78: inference completed in 6 steps. Fidelity score: 0.9592793267718457\n",
            "\n",
            "|01> - |10>\n",
            "Episode 13: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 19: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 20: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 23: inference completed in 11 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 24: inference completed in 11 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 34: inference completed in 13 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 36: inference completed in 11 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 37: inference completed in 11 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 50.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 25: inference completed in 3 steps. Fidelity score: 0.9999999999999996\n",
            "\n",
            "|01> + |10>\n",
            "Episode 17: inference completed in 9 steps. Fidelity score: 0.8871843784251533\n",
            "Episode 27: inference completed in 12 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 56: inference completed in 14 steps. Fidelity score: 0.8560095264191646\n",
            "Episode 88: inference completed in 9 steps. Fidelity score: 0.9829629131445343\n",
            "Episode 93: inference completed in 8 steps. Fidelity score: 0.8535533905932737\n",
            "\n",
            "|00> - |11>\n",
            "Episode 13: inference completed in 13 steps. Fidelity score: 0.8705127018922189\n",
            "Episode 21: inference completed in 14 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 22: inference completed in 14 steps. Fidelity score: 0.8750000000000002\n",
            "Episode 27: inference completed in 15 steps. Fidelity score: 0.8557581518689042\n",
            "Episode 57: inference completed in 18 steps. Fidelity score: 0.8557581518689036\n",
            "Episode 58: inference completed in 18 steps. Fidelity score: 0.8557581518689036\n",
            "Episode 98: inference completed in 18 steps. Fidelity score: 0.9829629131445341\n",
            "\n",
            "|01> - |10>\n",
            "Episode 65: inference completed in 16 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 67: inference completed in 7 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 68: inference completed in 7 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 91: inference completed in 12 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 92: inference completed in 11 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 93: inference completed in 11 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 94: inference completed in 11 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 50.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 62: inference completed in 19 steps. Fidelity score: 0.9330127018922187\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 0: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 24: inference completed in 15 steps. Fidelity score: 0.860092549001467\n",
            "Episode 30: inference completed in 7 steps. Fidelity score: 0.9171168834528284\n",
            "Episode 38: inference completed in 11 steps. Fidelity score: 0.8950197965407488\n",
            "Episode 52: inference completed in 18 steps. Fidelity score: 0.9872221848584001\n",
            "Episode 72: inference completed in 10 steps. Fidelity score: 0.8535533905932733\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 80.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "\n",
            "|01> + |10>\n",
            "Episode 92: inference completed in 13 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 93: inference completed in 13 steps. Fidelity score: 0.8705127018922191\n",
            "Episode 95: inference completed in 15 steps. Fidelity score: 0.9829629131445337\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 55: inference completed in 11 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 69: inference completed in 18 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 70: inference completed in 16 steps. Fidelity score: 0.9171168834528289\n",
            "Episode 75: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 76: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 77: inference completed in 9 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 80.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 6: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 11: inference completed in 3 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 14: inference completed in 5 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 15: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 16: inference completed in 3 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 17: inference completed in 3 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 32: inference completed in 15 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 98: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 99: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "|01> + |10>\n",
            "\n",
            "|00> - |11>\n",
            "Episode 10: inference completed in 11 steps. Fidelity score: 0.8535533905932735\n",
            "\n",
            "|01> - |10>\n",
            "Episode 18: inference completed in 10 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 31: inference completed in 15 steps. Fidelity score: 0.9061152816976316\n",
            "Episode 36: inference completed in 13 steps. Fidelity score: 0.8535533905932737\n",
            "Episode 90: inference completed in 10 steps. Fidelity score: 0.933012701892219\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 80.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 3: inference completed in 14 steps. Fidelity score: 1.0\n",
            "Episode 4: inference completed in 13 steps. Fidelity score: 0.9999999999999989\n",
            "Episode 63: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 66: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 68: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 69: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 86: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 89: inference completed in 2 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "|01> + |10>\n",
            "Episode 36: inference completed in 12 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 37: inference completed in 12 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 46: inference completed in 15 steps. Fidelity score: 0.8886047162271478\n",
            "Episode 47: inference completed in 15 steps. Fidelity score: 0.8886047162271478\n",
            "Episode 93: inference completed in 17 steps. Fidelity score: 0.933012701892219\n",
            "\n",
            "|00> - |11>\n",
            "Episode 8: inference completed in 17 steps. Fidelity score: 0.8750000000000004\n",
            "Episode 48: inference completed in 9 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 49: inference completed in 9 steps. Fidelity score: 0.8535533905932733\n",
            "\n",
            "|01> - |10>\n",
            "Episode 32: inference completed in 7 steps. Fidelity score: 0.875\n",
            "Episode 85: inference completed in 18 steps. Fidelity score: 0.961192875062926\n",
            "Episode 96: inference completed in 13 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 97: inference completed in 13 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 100.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 2: inference completed in 11 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 12: inference completed in 7 steps. Fidelity score: 1.0\n",
            "Episode 15: inference completed in 17 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 38: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 41: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 42: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 43: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 44: inference completed in 11 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> + |10>\n",
            "Episode 81: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|00> - |11>\n",
            "Episode 59: inference completed in 16 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 61: inference completed in 16 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 62: inference completed in 16 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 63: inference completed in 16 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 75: inference completed in 6 steps. Fidelity score: 0.9999999999999996\n",
            "\n",
            "|01> - |10>\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 100.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 91: inference completed in 19 steps. Fidelity score: 0.9330127018922194\n",
            "\n",
            "|01> + |10>\n",
            "Episode 12: inference completed in 8 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 15: inference completed in 8 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 17: inference completed in 7 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 18: inference completed in 7 steps. Fidelity score: 0.8749999999999998\n",
            "Episode 21: inference completed in 7 steps. Fidelity score: 0.875\n",
            "\n",
            "|00> - |11>\n",
            "Episode 52: inference completed in 4 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 53: inference completed in 5 steps. Fidelity score: 0.9330127018922196\n",
            "Episode 65: inference completed in 14 steps. Fidelity score: 0.8519785652108383\n",
            "\n",
            "|01> - |10>\n",
            "Episode 20: inference completed in 8 steps. Fidelity score: 0.8705127018922195\n",
            "Episode 21: inference completed in 8 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 22: inference completed in 9 steps. Fidelity score: 0.9171168834528286\n",
            "Episode 23: inference completed in 9 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 24: inference completed in 10 steps. Fidelity score: 0.8535533905932733\n",
            "Episode 25: inference completed in 8 steps. Fidelity score: 0.933012701892219\n",
            "Episode 26: inference completed in 11 steps. Fidelity score: 0.9171168834528282\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 100.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 6: inference completed in 10 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|01> + |10>\n",
            "Episode 44: inference completed in 19 steps. Fidelity score: 0.8736915966939676\n",
            "Episode 49: inference completed in 5 steps. Fidelity score: 0.9999999999999996\n",
            "Episode 53: inference completed in 16 steps. Fidelity score: 0.8557581518689031\n",
            "Episode 54: inference completed in 16 steps. Fidelity score: 0.8557581518689031\n",
            "Episode 60: inference completed in 18 steps. Fidelity score: 0.8998196448143736\n",
            "Episode 61: inference completed in 18 steps. Fidelity score: 0.8998196448143736\n",
            "\n",
            "|00> - |11>\n",
            "Episode 52: inference completed in 14 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 53: inference completed in 9 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> - |10>\n",
            "Episode 59: inference completed in 9 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 150.0, 'step_size': 0.0001}\n",
            "|00> + |11>\n",
            "Episode 27: inference completed in 13 steps. Fidelity score: 0.8600925490014673\n",
            "Episode 93: inference completed in 12 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "Episode 63: inference completed in 17 steps. Fidelity score: 0.8624679399638604\n",
            "Episode 79: inference completed in 19 steps. Fidelity score: 0.8969880219117206\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 85: inference completed in 7 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 150.0, 'step_size': 0.0005}\n",
            "|00> + |11>\n",
            "Episode 32: inference completed in 18 steps. Fidelity score: 0.9330127018922185\n",
            "Episode 63: inference completed in 10 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "|01> + |10>\n",
            "Episode 6: inference completed in 18 steps. Fidelity score: 0.8557581518689042\n",
            "Episode 20: inference completed in 6 steps. Fidelity score: 0.8535533905932735\n",
            "Episode 21: inference completed in 15 steps. Fidelity score: 0.9171168834528284\n",
            "\n",
            "|00> - |11>\n",
            "Episode 3: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 6: inference completed in 5 steps. Fidelity score: 0.9999999999999998\n",
            "Episode 9: inference completed in 18 steps. Fidelity score: 0.9215277310730006\n",
            "Episode 21: inference completed in 15 steps. Fidelity score: 0.9105084955064687\n",
            "\n",
            "|01> - |10>\n",
            "Episode 22: inference completed in 11 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 32: inference completed in 9 steps. Fidelity score: 0.875\n",
            "Episode 65: inference completed in 7 steps. Fidelity score: 0.9330127018922194\n",
            "Episode 67: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "\n",
            "\n",
            "{'negative_reward': -20.0, 'positive_reward': 150.0, 'step_size': 5e-05}\n",
            "|00> + |11>\n",
            "Episode 21: inference completed in 12 steps. Fidelity score: 0.9327888251536718\n",
            "Episode 49: inference completed in 3 steps. Fidelity score: 0.9999999999999998\n",
            "\n",
            "|01> + |10>\n",
            "Episode 30: inference completed in 12 steps. Fidelity score: 0.8688085690790635\n",
            "Episode 97: inference completed in 8 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 98: inference completed in 8 steps. Fidelity score: 0.8705127018922193\n",
            "Episode 99: inference completed in 8 steps. Fidelity score: 0.8705127018922193\n",
            "\n",
            "|00> - |11>\n",
            "\n",
            "|01> - |10>\n",
            "Episode 16: inference completed in 12 steps. Fidelity score: 0.8746994080239555\n",
            "Episode 17: inference completed in 12 steps. Fidelity score: 0.9330127018922192\n",
            "Episode 80: inference completed in 11 steps. Fidelity score: 0.9829629131445341\n",
            "\n",
            "\n",
            "CPU times: user 1h 41min 47s, sys: 2min 3s, total: 1h 43min 51s\n",
            "Wall time: 1h 41min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF5Gafz_Q2aA"
      },
      "source": [
        "path = \"tuning.txt\"\n",
        "\n",
        "with open(path, 'w+') as f:\n",
        "  f.write(\"Arguments \\n\")\n",
        "  f.write(f\"Tolerance: {TOLERANCE} - Training episodes: {TRAINING_EPISODES} - Offline updates: {NUM_OFFLINE_UPDATES}\\n\\n\")\n",
        "\n",
        "  f.write(\"\\t\".join([\"Bell state\", \"parameters\", \"number of gates\", \"fidelity\", \"optimality_type\"]))\n",
        "  f.write(\"\\n\")\n",
        "  for col in gridsearch_df:\n",
        "    f.write(col + \"\\t\")\n",
        "    f.write(f\"{gridsearch_df.loc['params', col][np.argmin(gridsearch_df.loc['num_gates', col])]}\\t\")\n",
        "    f.write(f\"{gridsearch_df.loc['num_gates', col][np.argmin(gridsearch_df.loc['num_gates', col])]}\\t\")\n",
        "    f.write(f\"{gridsearch_df.loc['fidelity', col][np.argmin(gridsearch_df.loc['num_gates', col])]}\\t\")\n",
        "    f.write(\"num_gates \\n\")\n",
        "\n",
        "    f.write(col + \"\\t\")\n",
        "    f.write(f\"{gridsearch_df.loc['params', col][np.argmax(gridsearch_df.loc['fidelity', col])]}\\t\")\n",
        "    f.write(f\"{gridsearch_df.loc['num_gates', col][np.argmax(gridsearch_df.loc['fidelity', col])]}\\t\")\n",
        "    f.write(f\"{gridsearch_df.loc['fidelity', col][np.argmax(gridsearch_df.loc['fidelity', col])]}\\t\")\n",
        "    f.write(\"fidelity \\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uf9YiSkSRvX1",
        "outputId": "30e3748b-779a-4dc6-8c55-fbffa30e5d03"
      },
      "source": [
        "files.download(path)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0b677edd-ed21-4c38-b84c-7bd739ee49ef\", \"tuning.txt\", 1022)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW49SU5RXCe3"
      },
      "source": [
        "Best Params:  \n",
        "`{'negative_reward': -6, 'positive_reward': 150, 'step_size': 0.0001}`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_Sp4QyeQQwc"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kijLuLg7N5Kb",
        "outputId": "5b289751-45e7-4287-a59f-f292b27be6cb"
      },
      "source": [
        "for rep, bell_state in bell_dict.items():\n",
        "  print(\"Bell state: \" +  rep)\n",
        "  start = [1, 0, 0, 0]\n",
        "  target = bell_state\n",
        "\n",
        "  experiment = Experiment(start, target, TOLERANCE, TRAINING_EPISODES, STEP_SIZE, NUM_OFFLINE_UPDATES,\n",
        "                          negative_reward = -6, positive_reward = 100)\n",
        "  circuit_gates, terminal_state = experiment.run_experiment()\n",
        "  compare_circuits(circuit_gates, terminal_state, QuantumState(target), PATH)\n",
        "  print(\"\")\n",
        "\n",
        "  sns.heatmap(experiment._agent._W)\n",
        "  plt.show()\n",
        "  print(\"\")\n",
        "  print(\"\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bell state: |00> + |11>\n",
            "Approximate state: [-0.427+0.11j   0.148+0.333j -0.376-0.508j -0.363+0.376j]\n",
            "Target state: [0.707 0.    0.    0.707]\n",
            "Fidelity score: 0.4300762524126555. Number of gates: 1001\n",
            "\n",
            "q0: ───I───────Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───I────────────I────────────Rx(0.667π)───I────────────I──────────I──────────Rz(0.333π)───Rx(π)───I──────────Ry(0.667π)───I────────────I────────────I───────I────────────I────────────I────────────Ry(π)───Rx(0.333π)───Rx(0.333π)───Ry(0.333π)───I────────────Rx(0.333π)───I───────Rz(0.333π)───Rx(π)───Ry(0.667π)───I───────I────────────Rx(0.667π)───Ry(0.667π)───I────────────I────────────I───────Rx(0.667π)───Ry(0.667π)───I────────────Rx(0.667π)───Ry(0.667π)───I────────────I────────────I───────I──────────Rx(0.25π)───Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I────────────I───────I──────────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────Ry(0.667π)───Ry(0.667π)───I───────Ry(0.667π)───I───────\n",
            "\n",
            "q1: ───Ry(π)───I───────────I───────────I───────────I───────────I───────────Ry(0.667π)───Ry(0.667π)───I────────────Ry(0.667π)───Ry(0.5π)───Ry(0.5π)───I────────────I───────Rx(0.5π)───I────────────Ry(0.667π)───Rz(0.667π)───Ry(π)───Ry(0.667π)───Ry(0.667π)───Ry(0.667π)───I───────I────────────I────────────I────────────Ry(0.667π)───I────────────Rz(π)───I────────────I───────I────────────Rx(π)───Rz(0.667π)───I────────────I────────────Ry(0.667π)───Rz(0.667π)───Ry(π)───I────────────I────────────Rz(0.667π)───I────────────I────────────Ry(0.667π)───Rz(0.667π)───Ry(π)───Rz(0.5π)───I───────────I────────────I────────────Ry(π)───I────────────Rz(0.667π)───Ry(π)───Rz(0.5π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───I────────────I────────────Ry(π)───I────────────Ry(π)───\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Bell state: |01> + |10>\n",
            "Approximate state: [-0.162-0.027j  0.324+0.739j  0.358+0.401j -0.101-0.149j]\n",
            "Target state: [0.    0.707 0.707 0.   ]\n",
            "Fidelity score: 0.8829195372183342. Number of gates: 826\n",
            "\n",
            "q0: ───I────────────Rx(π)───Rx(π)───I──────────I──────────I──────────Rx(π)───I───────────I───────────I───────────Rx(π)───Ry(0.333π)───Ry(0.333π)───I──────────I──────────I──────────Rx(0.667π)───Ry(π)───Rz(0.5π)───Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(π)───I──────────I──────────Rx(π)───I───────────I───────────I────────────Rx(0.333π)───Ry(0.25π)───I────────────Rx(0.333π)───I────────────Rx(π)───I───────────Rx(π)───Ry(0.333π)───Ry(0.333π)───Ry(0.333π)───I────────────I──────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───I───────────I──────────I──────────I──────────I──────────I──────────I──────────I──────────Rz(π)───I──────────I──────────I──────────Rx(π)───I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.25π)───Rz(0.5π)───Rx(0.667π)───I───────────I───────────I───────────I───────────Rx(0.333π)───Ry(0.333π)───I────────────I──────────I──────────I──────────I──────────I──────────I──────────Rz(0.333π)───I──────────Rz(0.5π)───I──────────Rx(π)───I───────────Ry(0.333π)───Ry(0.333π)───Ry(0.333π)───I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rz(π)───I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.667π)───I──────────I──────────I──────────I──────────I──────────I──────────I────────────I──────────Ry(π)───Rz(0.5π)───Rz(0.5π)───I──────────Rx(0.667π)───I──────────Rx(0.667π)───I──────────I──────────I──────────Rz(0.5π)───I──────────Rx(0.25π)───Rx(0.25π)───I────────────Rx(0.667π)───I───────────I───────────Rz(π)───I──────────I──────────Ry(π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────Rx(π)───Rz(π)───I──────────Ry(π)───I──────────Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.25π)───Rz(0.5π)───I──────────Rx(0.25π)───Rx(π)───I───────────I───────────Ry(0.333π)───Ry(0.333π)───I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.25π)───Rx(0.667π)───Rz(0.5π)───Rx(0.667π)───I──────────I──────────I──────────Rz(0.5π)───I──────────Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────Ry(0.333π)───I────────────I──────────I────────────I──────────I──────────I──────────Rz(0.5π)───I──────────Rz(0.5π)───Rx(0.667π)───I──────────I──────────I──────────Rz(π)───I──────────I──────────Ry(π)───I──────────Rz(π)───I──────────I──────────Rx(π)───Rx(π)───Ry(0.333π)───Ry(0.333π)───Ry(0.333π)───I────────────I──────────I──────────I──────────I───────────I───────────I───────────I───────────I───────────Ry(0.333π)───I────────────I────────────I──────────I──────────Ry(π)───Rz(π)───I──────────I──────────Rx(π)───I───────────I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───Rz(0.5π)───I──────────Rx(0.667π)───Rz(0.5π)───I──────────I───────────I───────────I───────────I───────────I───────────I────────────Rx(0.667π)───Ry(0.25π)───I────────────I────────────I──────────I──────────I──────────I──────────I──────────I──────────I──────────I──────────I────────────I────────────I──────────I──────────I──────────I──────────I──────────Rz(π)───I──────────I──────────I──────────Ry(π)───Rx(0.667π)───I───────────Rz(π)───I──────────I──────────I──────────Ry(π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───I───────────I──────────I──────────I──────────Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rx(0.333π)───Rz(0.667π)───Ry(0.25π)───Ry(0.25π)───I────────────Ry(π)───I──────────Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────Ry(0.333π)───I────────────I────────────I──────────I──────────I──────────I──────────I──────────I──────────Rz(0.5π)───Ry(π)───Rz(π)───I──────────I──────────Ry(π)───I──────────Rz(π)───I──────────I──────────I──────────Ry(π)───Rx(π)───I──────────Rx(0.667π)───I──────────I──────────I──────────I──────────Rz(π)───I──────────I──────────I──────────Rx(π)───I───────────Rx(π)───Rx(0.667π)───I──────────I──────────I────────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I────────────I────────────I──────────I──────────I──────────I──────────I──────────Rz(0.5π)───I──────────I───────────I────────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(π)───I──────────I──────────Rx(π)───I───────────I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(π)───I──────────Rx(0.667π)───I────────────Rx(0.667π)───I───────────I───────────I───────────I──────────I──────────I──────────I────────────Ry(0.667π)───Rx(π)───Rx(π)───Ry(0.333π)───Ry(0.333π)───Ry(0.333π)───Ry(0.667π)───Ry(π)───I──────────Rz(0.5π)───I──────────Rz(0.5π)───Rx(0.667π)───I───────────I───────────I───────────Ry(0.25π)───I────────────I────────────I──────────I──────────Ry(π)───I──────────Rz(π)───I──────────I──────────Ry(π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────Ry(0.333π)───I────────────I──────────I──────────Rx(0.333π)───Rz(0.667π)───Ry(0.25π)───Ry(0.25π)───Rx(π)───I──────────I──────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.667π)───Rx(0.667π)───I───────────I───────────Rz(π)───I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.667π)───I──────────I──────────I──────────I──────────I──────────Ry(π)───I──────────I──────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───I───────────Rz(π)───I──────────I──────────Ry(π)───I──────────Rx(0.25π)───Rx(0.667π)───I───────────I───────────Rz(π)───I──────────I──────────Ry(π)───I──────────Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Ry(0.333π)───Ry(0.333π)───Ry(0.333π)───I────────────I──────────I──────────Rx(0.667π)───Ry(π)───Ry(π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───I───────────I───────────I───────────Ry(0.333π)───Ry(0.333π)───Ry(0.25π)───I────────────Ry(0.667π)───I──────────Ry(π)───Rz(0.5π)───I──────────I────────────I───────────I────────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────Rx(0.667π)───Rz(π)───I──────────Ry(π)───I──────────Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───I──────────I──────────I──────────I──────────I──────────Ry(π)───I──────────Rx(π)───I───────────I───────────I───────────I───────────I────────────I──────────I──────────I──────────I──────────I──────────I──────────Rz(0.333π)───I──────────Ry(π)───I──────────I──────────I────────────Ry(0.667π)───Ry(π)───I──────────I──────────I────────────I────────────I──────────I──────────I──────────I──────────I──────────I──────────I──────────I──────────I────────────Ry(0.667π)───Ry(π)───I──────────Rz(0.5π)───I──────────I────────────Rz(0.5π)───Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────Ry(0.333π)───I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────Rx(0.333π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───Rx(0.667π)───Rx(0.333π)───Rx(0.333π)───Ry(0.25π)───Rz(0.667π)───Ry(0.25π)───Ry(0.25π)───Rx(π)───I──────────I──────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────Rx(π)───Ry(0.333π)───Ry(0.333π)───I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I───────────I────────────I──────────I────────────I──────────I──────────I──────────Rz(0.5π)───I──────────Rz(0.5π)───I──────────I───────────I───────────I───────────I───────────I────────────Rx(0.667π)───Ry(0.25π)───Ry(0.25π)───I────────────I────────────I──────────I──────────I──────────I──────────I──────────Rz(π)───I──────────I──────────Ry(π)───Rx(0.667π)───Rx(0.667π)───I───────────I──────────I──────────I──────────I──────────Rz(π)───I──────────I──────────Rx(π)───I───────────I────────────I────────────I──────────I──────────Ry(π)───Rz(0.5π)───I──────────Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───I──────────I──────────I──────────I──────────Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────Rx(π)───Ry(0.333π)───Ry(0.333π)───Ry(0.333π)───I──────────I──────────I──────────Rx(0.667π)───I───────────I───────────Ry(0.333π)───Ry(0.25π)───I────────────I──────────I──────────I──────────I──────────Rz(π)───I──────────I──────────I──────────Ry(π)───Rx(0.25π)───Rz(π)───I──────────I──────────Ry(π)───I──────────I──────────I────────────I────────────I──────────Ry(π)───I──────────I──────────I───────────I───────────I───────────I───────────Rz(0.5π)───Rx(0.667π)───@───Rz(0.5π)───I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I────────────Rx(0.667π)───I───────────I───────────I───────────I───────────Ry(0.333π)───I────────────I──────────Rx(0.667π)───I───────────I───────────I───────────I───────────Rx(0.667π)───I────────────I───────────I───────────Rx(0.667π)───I───────────I───────────I───────────I────────────I──────────Rx(0.667π)───I───────────I───────────Rx(0.667π)───I───────────Ry(π)───\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     │\n",
            "q1: ───Rz(0.667π)───I───────I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I───────I────────────I────────────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I────────────I───────I──────────I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I───────Rx(0.5π)───Rx(0.5π)───I───────Ry(0.25π)───Ry(0.25π)───Rz(0.667π)───I────────────I───────────Ry(0.667π)───I────────────Rz(0.667π)───I───────Ry(0.25π)───I───────I────────────I────────────I────────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I───────────I────────────I────────────Rx(0.25π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Ry(0.5π)───Rz(0.5π)───Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I───────────I──────────I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────I────────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───I────────────Rx(0.5π)───I──────────Rx(0.5π)───I───────Rx(0.25π)───I────────────I────────────I────────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I────────────Rz(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Ry(0.667π)───Rx(0.5π)───I───────I──────────I──────────Rx(0.5π)───I────────────Rz(0.5π)───I────────────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I──────────Rx(0.5π)───I───────────I───────────Rz(0.333π)───I────────────Rx(0.25π)───Rx(0.25π)───I───────Rx(0.5π)───Rx(0.5π)───I───────Rx(0.5π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I───────I───────Rx(0.5π)───I───────Rx(0.5π)───I──────────Rx(0.5π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I───────────I──────────Rx(0.5π)───I───────────I───────Ry(0.25π)───Ry(0.25π)───I────────────I────────────Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I───────────I────────────I──────────I────────────Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───I──────────Rx(0.5π)───I──────────Rx(0.5π)───I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────Ry(0.667π)───Rx(0.5π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I──────────Rx(0.5π)───I──────────I────────────Rz(0.5π)───Rx(0.5π)───Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───I───────Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───I───────I───────I────────────I────────────I────────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I───────Rx(0.5π)───Rx(0.5π)───I───────Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────I──────────Rx(0.5π)───I────────────I──────────Rx(0.5π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Rz(0.333π)───I────────────I───────────Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────I────────────Rx(0.25π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────I───────────I────────────I────────────Rx(0.25π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────────I───────────I────────────I────────────I────────────I────────────I───────────I───────────Ry(0.667π)───I───────Rx(0.5π)───I──────────Rx(0.5π)───I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────Rz(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I──────────I───────I───────Rx(0.5π)───Rx(0.5π)───I───────Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────I───────Rz(0.5π)───I────────────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────Ry(0.25π)───I───────I────────────Rx(0.5π)───Rx(0.5π)───Rz(0.333π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───I──────────Rx(0.5π)───Ry(0.25π)───Rz(0.333π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I───────Rx(0.5π)───Rx(0.5π)───I───────Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I───────Rx(0.5π)───I────────────Rz(0.333π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───I────────────I───────I───────I────────────I────────────I────────────I────────────I───────Rx(0.5π)───I──────────Rx(0.5π)───I──────────I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───I───────────Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───I───────Rx(0.5π)───I────────────Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I────────────I────────────I───────────I───────────I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I────────────I────────────Rx(0.25π)───Rx(0.25π)───I───────Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I────────────Rz(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───I───────────I───────────I───────────I────────────Rx(0.25π)───I───────Rx(0.5π)───Rx(0.5π)───I───────Rx(0.5π)───I───────────I────────────Rx(0.25π)───Rx(0.25π)───I───────Rx(0.5π)───Rx(0.5π)───I───────Rx(0.5π)───I───────────I────────────I────────────I────────────I────────────I────────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I────────────I───────I───────I───────────I────────────I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────I────────────I───────────Ry(0.667π)───I────────────Rx(0.5π)───I───────I──────────Rx(0.5π)───Rz(0.333π)───Ry(0.25π)───Rz(0.333π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────I───────Rx(0.5π)───I───────Rx(0.5π)───I──────────Rx(0.5π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I───────────I───────────I────────────Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────Rx(0.5π)───I───────Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───I────────────Rx(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───I────────────I───────Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───I────────────I───────Rx(0.5π)───I──────────Rx(0.5π)───Rz(0.333π)───I──────────I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I───────────I───────────I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Rz(0.333π)───Rz(0.333π)───I────────────I───────────I───────────I────────────Rx(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────I────────────I────────────I────────────I───────────I────────────I───────────I───────────I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I───────I────────────I────────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Rx(0.5π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I──────────Rx(0.5π)───I──────────Rx(0.5π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Rz(0.333π)───I────────────I───────────I───────────Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───Rx(0.5π)───Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───I───────I────────────I────────────Rx(0.25π)───Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───I───────Ry(0.25π)───Ry(0.667π)───Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───I───────I──────────Rx(0.5π)───I───────────I────────────I────────────Rz(0.5π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I──────────Rx(0.5π)───I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I───────I────────────I────────────I────────────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I────────────Ry(0.25π)───Ry(0.25π)───I────────────I───────────Ry(0.667π)───Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───Rz(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.5π)───I───────I───────────I───────Rx(0.5π)───Rx(0.5π)───I───────Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───Ry(0.667π)───Rx(0.5π)───I───────Rz(0.5π)───Rz(0.5π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I──────────I────────────X───I──────────Rx(0.5π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Rz(0.333π)───I────────────Rx(0.25π)───Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────Ry(0.667π)───Rx(0.5π)───I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I────────────Rz(0.333π)───Ry(0.25π)───Ry(0.25π)───I────────────Rx(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(0.667π)───Rx(0.5π)───I────────────Ry(0.25π)───Ry(0.25π)───I────────────Ry(0.25π)───I───────\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Bell state: |00> - |11>\n",
            "Approximate state: [ 0.   +0.j     0.259-0.966j  0.   -0.j    -0.   -0.j   ]\n",
            "Target state: [ 0.707  0.     0.    -0.707]\n",
            "Fidelity score: 1.5407439555097876e-32. Number of gates: 1001\n",
            "\n",
            "q0: ───Rz(0.667π)───Ry(0.5π)───Ry(0.5π)───I───────────I───────────I───────Rz(0.667π)───Rz(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rx(π)───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───@───\n",
            "                                                                                                                                                            │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │   │\n",
            "q1: ───I────────────I──────────I──────────Rz(0.25π)───Rz(0.25π)───Rx(π)───I────────────I────────────I───────────I───────────I───────────I───────────I───────X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───X───\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Bell state: |01> - |10>\n",
            "Approximate state: [ 0.069-0.182j  0.413+0.408j -0.583-0.444j  0.078-0.285j]\n",
            "Target state: [ 0.     0.707 -0.707  0.   ]\n",
            "Fidelity score: 0.8596986815789602. Number of gates: 665\n",
            "\n",
            "q0: ───Rz(0.5π)───Ry(0.5π)───Ry(0.25π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rz(0.5π)───Rx(0.25π)───Rz(0.5π)───Rx(0.25π)───I───────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───I──────────I──────────I────────────Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───Rx(0.5π)───Rx(0.667π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.5π)───Rx(0.5π)───Rx(0.667π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───Rx(0.667π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(π)───Rx(0.667π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(π)───Rx(0.667π)───I────────────@───Rx(0.5π)───Rx(0.667π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(π)───Rx(0.667π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(π)───I───────────Rx(0.5π)───Rx(0.667π)───I────────────Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rx(π)───Rx(0.5π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(π)───I───────────Rx(0.5π)───Rx(0.5π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rz(0.25π)───Rz(0.25π)───Rx(0.667π)───Rz(0.25π)───Rx(π)───I────────────I────────────Rx(0.667π)───I────────────I────────────I───────────I───────────Ry(π)───Rz(0.25π)───Rz(0.5π)───Rz(0.5π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───I───────────I───────────Ry(π)───I────────────Ry(0.5π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.5π)───I──────────I──────────Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rx(π)───Ry(0.333π)───Ry(0.333π)───I────────────Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───I────────────Rz(0.25π)───Rz(0.25π)───I───────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rz(0.25π)───Ry(0.667π)───Rz(0.5π)───I──────────Rx(0.25π)───Rx(0.25π)───Ry(π)───Ry(π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───I────────────Rx(0.667π)───I────────────I────────────Rx(0.667π)───I────────────I────────────I───────────I───────────Ry(π)───Rz(0.5π)───Rz(0.5π)───Rz(π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Rz(0.5π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───Rz(0.5π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───I───────────I───────────Ry(π)───I────────────I────────────Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───I──────────Rx(0.25π)───Rx(0.25π)───Ry(π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.5π)───Ry(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───I──────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───I───────────I───────────I───────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───I───────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───I───────────I───────────I───────────I───────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───I──────────Ry(π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rx(0.667π)───Rz(0.25π)───I───────────Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Ry(0.5π)───Rz(0.25π)───I───────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rz(0.25π)───I───────────I───────────I───────────Rx(π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───I──────────I──────────I────────────I────────────I────────────Rx(0.667π)───I────────────Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───I──────────Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───Ry(0.5π)───I────────────I────────────Rz(π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───Ry(0.333π)───I────────────I────────────@───Ry(π)───I────────────Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───I──────────I────────────I────────────I────────────I────────────I───────────I───────────Ry(π)───I────────────I────────────I───────────Ry(π)───I────────────Ry(0.5π)───Rz(0.25π)───Rz(0.25π)───Ry(0.5π)───Rz(0.25π)───I────────────Rx(π)───I────────────Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.5π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.5π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───I───────────Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───I────────────I────────────I───────────I───────────Ry(π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───I────────────I───────────I───────────Ry(π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.5π)───I──────────Rx(0.25π)───Ry(π)───I───────────Ry(π)───I────────────I────────────I───────────I───────────Ry(π)───Rz(0.25π)───Rz(0.25π)───Rz(0.5π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───I───────────Ry(π)───I────────────I────────────Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rx(π)───I───────────I───────────Ry(π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(0.667π)───I───────────Ry(π)───I────────────I────────────Rx(0.667π)───Rx(0.667π)───Rz(0.25π)───Rx(0.667π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rx(π)───I───────────I───────────Ry(π)───Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Rz(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(π)───I───────────I───────────I───────────Ry(π)───I────────────Ry(π)───Rx(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(π)───Rx(0.667π)───I────────────Rx(0.667π)───I────────────I────────────Rz(0.25π)───Rz(0.25π)───Rz(0.25π)───Ry(0.667π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───I────────────Ry(0.5π)───Rz(0.25π)───Ry(0.5π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Rx(0.25π)───Ry(π)───I────────────\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   │                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         │\n",
            "q1: ───I──────────I──────────I───────────I────────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────I──────────I───────────I──────────I───────────Rx(π)───I───────────I───────────I───────────I───────────Ry(0.5π)───Ry(0.5π)───Rz(0.333π)───I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────I──────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I──────────I──────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I──────────I──────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I────────────I───────────I───────────I───────────I───────────I───────────I───────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────I────────────Ry(0.333π)───X───I──────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────Ry(0.25π)───I──────────I────────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────I──────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────Ry(0.25π)───I──────────I──────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I────────────I───────────I───────Rz(0.333π)───Rx(0.667π)───I────────────Ry(0.333π)───Ry(0.333π)───Ry(0.25π)───Ry(0.25π)───I───────I───────────I──────────I──────────I───────────I───────────I───────────I────────────Ry(0.25π)───Ry(0.25π)───I───────Ry(0.333π)───I──────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────Ry(0.667π)───I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I──────────Rx(0.5π)───Rx(0.5π)───I───────────I────────────I────────────I───────────I───────────I───────I────────────I────────────Ry(0.333π)───I───────────I───────────I───────────Rz(0.333π)───I───────────I───────────Ry(π)───I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I────────────I──────────Rx(0.5π)───I───────────I───────────I───────I───────Ry(0.333π)───I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────Rz(0.333π)───I────────────Ry(0.333π)───Rx(0.667π)───I────────────Ry(0.333π)───Ry(0.333π)───Ry(0.25π)───Ry(0.25π)───I───────I──────────I──────────I───────I───────────I───────────I───────────I───────────I───────────I────────────I──────────I───────────I───────────I───────I──────────I───────────I───────────I───────────I───────────I───────Ry(0.25π)───Ry(0.25π)───I───────Ry(0.333π)───Rz(0.333π)───I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────Rx(0.5π)───I───────────I───────────I───────Ry(0.667π)───I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I──────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────Rx(0.667π)───I───────────I───────────I───────────I───────────I───────────Ry(0.5π)───I───────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────Ry(0.25π)───Ry(0.25π)───Ry(π)───I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────Ry(π)───I───────────I───────────I───────────I───────────I───────────I───────────I────────────I───────────I───────────Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───Ry(π)───I───────────I───────────I───────────I───────────I───────────I────────────Rx(0.5π)───I───────Ry(0.667π)───I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I────────────I───────────Ry(0.25π)───I────────────I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────I──────────I───────────Ry(π)───I───────────I───────────I───────────I───────────I───────────I───────────I───────────I────────────I───────────Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I───────I────────────I───────────I───────────I───────────I───────────I───────────I───────────Ry(0.5π)───Ry(0.5π)───Ry(0.333π)───Ry(0.333π)───Rx(0.667π)───I────────────Ry(0.333π)───I───────────I───────────I───────────I───────────I───────────Ry(0.5π)───I────────────I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────I──────────Ry(0.333π)───Ry(0.333π)───I───────I───────────I───────────I───────────I───────────I───────────I───────I────────────Ry(0.333π)───Ry(0.333π)───X───I───────Ry(0.333π)───I───────────I───────────I───────────I───────────Ry(0.5π)───Ry(0.333π)───Ry(0.333π)───Rx(0.667π)───Ry(0.333π)───Ry(0.25π)───Ry(0.25π)───I───────Ry(0.333π)───Ry(0.333π)───Ry(0.25π)───I───────Ry(0.333π)───I──────────I───────────I───────────I──────────I───────────Rz(0.333π)───I───────Ry(0.667π)───I───────────I───────────I───────────I────────────I────────────I───────────I───────────I──────────I────────────I────────────I───────────I───────────I───────────I───────────I────────────I────────────I────────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I──────────I────────────I────────────I───────────I───────────I───────────I───────────I────────────Ry(0.25π)───I────────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────Ry(0.333π)───Ry(0.333π)───Ry(0.25π)───Ry(0.25π)───I───────I───────────I───────────I───────────I────────────I───────────I───────────I────────────Rz(0.333π)───Ry(0.25π)───Ry(0.25π)───I───────I───────────I───────────I───────────I───────────I────────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────I──────────Rx(0.5π)───I───────────I───────Ry(0.25π)───I───────Ry(0.333π)───Ry(0.333π)───Ry(0.25π)───Ry(0.25π)───I───────I───────────I───────────I──────────I────────────I───────────I───────────I───────────I────────────Ry(0.25π)───I───────Ry(0.333π)───Ry(0.667π)───I────────────I────────────I───────────I────────────I───────────I───────────I───────────I───────Ry(0.25π)───Ry(0.25π)───I───────I───────────I───────────I───────────I────────────I───────────I───────────I────────────I────────────I───────────I───────────I───────────I───────────I────────────Ry(0.25π)───I───────Ry(0.333π)───Ry(0.667π)───I────────────I────────────I───────────I────────────I───────────I───────────I───────────I───────Ry(0.25π)───Ry(0.25π)───I───────I───────────I───────────I───────────I────────────I───────────I───────────I───────Ry(0.25π)───Ry(0.25π)───Ry(0.25π)───I───────Ry(0.667π)───I───────I────────────I───────────I───────────I───────────I───────────I───────────I───────────I───────────I───────I────────────Ry(0.333π)───I────────────Ry(0.333π)───Rx(0.667π)───I───────────I───────────I───────────I────────────I───────────I───────────I───────────I───────────I───────Rx(0.667π)───I──────────I───────────I──────────I───────────I───────────I───────────I───────────I───────────I───────Ry(0.333π)───\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1SOmLK9O1mJ"
      },
      "source": [
        "files.download(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoEfGy_AxDmb"
      },
      "source": [
        "# Analysis and TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5-DR4p_QJ8o"
      },
      "source": [
        "Count the number of successes.\n",
        "Some summary statistics of this type using binning should be plotted\n",
        "In general this could be useful to compare different polcies\n",
        "Please build a systematic set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6yyJGq1J9Oh"
      },
      "source": [
        "Compare \n",
        "- Step size decrease (che e un concettoesistente in Deep lr ==> scheduler): è migliorativo?\n",
        "- behavioural policy: random o eps greedy?\n",
        "- Different rewards\n",
        "- Ragionare su perché il miglioramente non è costante, come invece vorrei,\n",
        "==> ho bisogno di generalizzare? no devo essere di successo solo su cio che ho visto in training\n",
        "Behaviour policy always exploring has been solution: try without.\n",
        "Nota: la ragione del comportamento oscillante da episodio a episodio è dovuto al fatto che gradient descent rischia di cadere in local optima ==> rallenta la convergenza a una policy ottimale. Quanto invece ho dei buoni seed esco di lì. \n",
        "Devo mediare o cosa? Posso anche mediare, ma dire che a noi serve un global optimum per trovare l'optimal path, non generalizzare. Chiedo a tizio.\n",
        "\n",
        "- Comparo diverse target policy da diversi behaviour!\n",
        "- testare experience replay per capire al meglio ogni stato. ==> mi serve o posso togliere?\n",
        "- Comparo numero di policy di successo rispetto a un approccio random: però la policy che imparo è imparata, il random no, cretino ==> quindi anche se e peggio in generale, basta sia buono una volta. Probabilmente il minimo che trovo è solo locale, ma è gia sufficiente, e il fatto che ne esca continuamente richiede soluzione a piu ampio spettro a cui non sono interessato ora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj7dwCD0J9Oi"
      },
      "source": [
        "Run an inference every N episodes and monitor the optimality of the behaviour\n",
        "We could add experience replay, since after a certain number of new episodes it doesn't work well anymore"
      ]
    }
  ]
}