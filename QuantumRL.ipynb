{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuantumRL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NV8sEgIgZisp",
        "hnWqxby5ZfY_",
        "kfmGXb2TZWpw"
      ],
      "authorship_tag": "ABX9TyMUmy22F8UUZBo9tYbEshCC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francescomontagna/Quantum-Reinforcement-Learning/blob/main/QuantumRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ywYaaLPmtL"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETGJGzcDIxwC"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import cmath\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import cm\n",
        "from functools import reduce"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWCQSEmAOUI3"
      },
      "source": [
        "# Introduction\n",
        "## Problems\n",
        "- Since we can access the features, and know the transition probability from a state to another, this RL protocol is model based.\n",
        "Note that this is in contrast with the uncertainty about a quantum state from the observator point of view: an observator can only access the collapsed state, having no access to the amplitudes. \n",
        "\n",
        "In the paper Girolami sent me, they explicitly account for this fact, setting up a model free protocol.  \n",
        "\n",
        "\n",
        "## Reward\n",
        "Il principale problema è la formulzione della reward. per ora, l'unica soluzione tale da portare risultati accettabili è stata:\n",
        "- reward = \"grande\" per stato terminal\n",
        "- reward < 0 per stato non terminal  \n",
        "\n",
        "L'aggiunta di reward negativa a punire ogni step che non portasse a uno stato terminale, è stato cruciale. Infatti, ho usato altri tipi di reward, ma tutte fallimentari  \n",
        "- fidelity\n",
        "- fidelity per stato terminale, altrimenti 0\n",
        "- \"grande\" per stato terminale, altrimenti 0  \n",
        "\n",
        "Tutti questi tentativi si sono mostrati fallimentari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8rsT6Mr7Zy"
      },
      "source": [
        "## Off Policy\n",
        "Sono dovuto ricorrere a un'approccio off policy, in quanto un approccio on policy non garantiva esplorazione sufficiente in uno spazio di ricerca così vasto. I risultati erano frtemente limitati, la matrice dei weight non vedeva mai alcune azioni, il cui valore rimaneva 0 per ogni features. I risultati erano in media peggiori di un' approccio Random.  \n",
        "Andando a usare una bahaviour policy completamente randomica, e una target policy completamente greedy, i risultati sono notavolmente migliorati. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-LCGYpUPpTm"
      },
      "source": [
        "# Quantum Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV8sEgIgZisp"
      },
      "source": [
        "### Qubit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjboXlFWG5EK"
      },
      "source": [
        "class Qubit:\n",
        "  def __init__(self, amplitudes):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      amplitudes (np.array): amplitudes of the |0>, |1> vectors\n",
        "    \"\"\"\n",
        "    error = \"Error: sum of squared amplitudes must be = 1\"\n",
        "    assert math.isclose(reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, amplitudes)), 1, rel_tol = 1e-2), error\n",
        "    self._amplitudes = amplitudes\n",
        "\n",
        "  def qubit(self):\n",
        "    return self._amplitudes\n",
        "    \n",
        "\n",
        "class Basis(Qubit):\n",
        "  def __init__(self, index):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      index: index of the position = 1\n",
        "    \"\"\"\n",
        "    amplitudes = np.zeros((2, ))\n",
        "    amplitudes[index] += 1\n",
        "    super().__init__(amplitudes)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnWqxby5ZfY_"
      },
      "source": [
        "### Quantum State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRBaWNuZyhgp"
      },
      "source": [
        "class QuantumState:\n",
        "  def __init__(self, amplitudes): \n",
        "\n",
        "    # We assume computational basis\n",
        "    self._basis = {\n",
        "        '00': [Basis(0), Basis(0)],\n",
        "        '01': [Basis(0), Basis(1)],\n",
        "        '10': [Basis(1), Basis(0)],\n",
        "        '11': [Basis(1), Basis(1)],\n",
        "    }\n",
        "\n",
        "    a1, a2, a3, a4 = amplitudes\n",
        "    self._amplitudes = {\n",
        "        '00': a1,\n",
        "        '01': a2,\n",
        "        '10': a3,\n",
        "        '11': a4\n",
        "    }\n",
        "    \n",
        "    self._keys = list(self._basis.keys())\n",
        "\n",
        "    error = \"Error: sum of squared amplitudes must be = 1\"\n",
        "    val = reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, amplitudes))\n",
        "    assert math.isclose(val, 1, rel_tol = 1e-2), error + f\" instead is {val}\"\n",
        "\n",
        "  def get_amplitudes(self):\n",
        "    return np.array(list(self._amplitudes.values()))\n",
        "\n",
        "  def get_features(self):\n",
        "    real = np.real(list(self._amplitudes.values()))\n",
        "    imag = np.imag(list(self._amplitudes.values()))\n",
        "    return np.concatenate((real, imag))\n",
        "\n",
        "  def apply_gate(self, gate, inplace = False):\n",
        "    updated_amplitudes = gate.apply(self)\n",
        "    if inplace:\n",
        "      self._amplitudes = updated_amplitudes\n",
        "      return None\n",
        "\n",
        "    return QuantumState(list(updated_amplitudes.values()))\n",
        "\n",
        "  def fidelity_score(self, other):\n",
        "    # TODO: check on nielsen, implement well.\n",
        "    # This implementation is from paper\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      other (QuantumState): measure the fidelity between self and another quantum state\n",
        "    Return:\n",
        "      fidelity (float): fidelity score between [0, 1]\n",
        "    \"\"\"\n",
        "    # Inner product can be computed in terms of matrix representation. Page 67 Nielsen-Chuang\n",
        "    return np.square(abs(np.matmul(np.conj(self.get_amplitudes()), other.get_amplitudes())))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rboUEAK3ZbWt"
      },
      "source": [
        "### Quantum Gates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HOc4Ouiockr"
      },
      "source": [
        "class QuantumGate:\n",
        "  def __init__(self, name, unitary, target):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "      unitary: 2x2 unitary operator\n",
        "      target: 0 or 1 to denote the qubit the matrix is acting on\n",
        "    \"\"\"\n",
        "    self._name = name\n",
        "    self._U = unitary.flatten()\n",
        "    self._target = target\n",
        "\n",
        "\n",
        "  def apply(self, quantum_state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      quantum_state (QuantumState): quantum state to which apply the quantum operator\n",
        "    Return:\n",
        "      updated (dict): didctionary with updated amplitudes\n",
        "    \"\"\"\n",
        "    # Directly implement update rule on the amplitudes for a 2 qubits case. \n",
        "    # NOTE: This approach is not scalable! Refine or use qiskit for more than 2 qubits\n",
        "    a_00, a_01, a_10, a_11 = quantum_state.get_amplitudes()\n",
        "    updated = dict()\n",
        "\n",
        "    if self._target == 0:\n",
        "      updated['00'] = self._U[0]*a_00 + self._U[1]*a_10\n",
        "      updated['01'] = self._U[0]*a_01 + self._U[1]*a_11\n",
        "      updated['10'] = self._U[2]*a_00 + self._U[3]*a_10\n",
        "      updated['11'] = self._U[2]*a_01 + self._U[3]*a_11\n",
        "\n",
        "    else:\n",
        "      updated['00'] = self._U[0]*a_00 + self._U[1]*a_01\n",
        "      updated['01'] = self._U[2]*a_00 + self._U[3]*a_01\n",
        "      updated['10'] = self._U[0]*a_10 + self._U[1]*a_11\n",
        "      updated['11'] = self._U[2]*a_10 + self._U[3]*a_11\n",
        "\n",
        "    # Check if amplitudes still satisfy condition\n",
        "    normalization = reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, updated.values()))\n",
        "    error = f\"Error: sum of squared amplitudes must be = 1.\\n Amplitudes: {list(updated.values())}, summing up to {normalization}\"\n",
        "    assert math.isclose(normalization, 1, rel_tol = 1e-2), error\n",
        "    \n",
        "    return updated\n",
        "\n",
        "\n",
        "class CNOT(QuantumGate):\n",
        "  def __init__(self, control):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      control (int): if 0, first qubit is the control, else second\n",
        "    Return:\n",
        "      result (QuantumState): quantum state with amplitudes modified\n",
        "    \"\"\"\n",
        "    self._control = control\n",
        "    super().__init__('cnot', np.array([[0, 1], [1, 0]]), 1-control)\n",
        "\n",
        "\n",
        "  def apply(self, quantum_state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      state (QuantumState): quantum state to which apply the quantum operator\n",
        "    Return:\n",
        "      result (QuantumState): quantum state with amplitudes modified\n",
        "    \"\"\"\n",
        "    # Directly implement update rule on the amplitudes for a 2 qubits case. \n",
        "    # NOTE: This approach is not scalable! Refine or use qiskit for more than 2 qubits\n",
        "    a_00, a_01, a_10, a_11 = quantum_state.get_amplitudes()\n",
        "    updated = dict()\n",
        "\n",
        "    if self._control == 0: # Then target = 2nd: if 1st qubit == 1, flip 2nd qubit.\n",
        "      updated['00'] = a_00\n",
        "      updated['01'] = a_01\n",
        "      updated['10'] = self._U[0]*a_10 + self._U[1]*a_11\n",
        "      updated['11'] = self._U[2]*a_10 + self._U[3]*a_11\n",
        "\n",
        "    if self._control == 1: # Then control = 1st: if 2nd qubit == 1, flip 1st qubit.\n",
        "      updated['00'] = self._U[0]*a_00 + self._U[1]*a_10\n",
        "      updated['01'] = self._U[0]*a_01 + self._U[1]*a_11\n",
        "      updated['10'] = a_10\n",
        "      updated['11'] = a_11\n",
        "\n",
        "    # Check if amplitudes still satisfy condition\n",
        "    normalization = reduce(lambda a, b: a+b, map(lambda a: abs(a)**2, updated.values()))\n",
        "    error = f\"Error: sum of squared amplitudes must be = 1.\\n Amplitudes: {list(updated.values())}, summing up to {normalization}\"\n",
        "    assert math.isclose(normalization, 1, rel_tol = 1e-2), error\n",
        "    \n",
        "    return updated"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmGXb2TZWpw"
      },
      "source": [
        "### Gates List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pus5TovHiETW"
      },
      "source": [
        "class Gates:\n",
        "  def __init__(self):\n",
        "    gates = dict()\n",
        "    self._num_gates = 0\n",
        "\n",
        "    # Useful\n",
        "    targets = [0, 1]\n",
        "    j = 1j # complex unit\n",
        "\n",
        "    gates['x0'] = QuantumGate('x0', np.array([[0, 1], [1, 0]]), 0)\n",
        "    self._num_gates += 1\n",
        "    gates['y0'] = QuantumGate('y0', np.array([[0, -1j], [1j, 0]]), 0)\n",
        "    self._num_gates += 1\n",
        "    gates['z0'] = QuantumGate('z0', np.array([[1, 0], [0, -1]]), 0)\n",
        "    self._num_gates += 1\n",
        "\n",
        "    ########### CNOT ###########\n",
        "    gates['CNOT'] = CNOT(control = 0)\n",
        "    self._num_gates += 1\n",
        "\n",
        "    ########### Rotations ###########\n",
        "    angles_names = ['pi', '2pi/3', 'pi/2', 'pi/3', 'pi/4']\n",
        "    angles_values = (math.pi / 2) * np.array([1, 2/3, 1/2, 1/3, 1/4])\n",
        "    angles = {k:v for k,v in zip(angles_names, angles_values)}\n",
        "\n",
        "    # Rx\n",
        "    for name, theta in angles.items():\n",
        "      for t in targets:\n",
        "        key = 'Rx' + str(t) + '(' + name + ')'\n",
        "        gates[key] = QuantumGate(key, np.array([[math.cos(theta), -j*math.sin(theta)],\n",
        "                                                      [-j*math.sin(theta), math.cos(theta)]]), t)\n",
        "        self._num_gates += 1\n",
        "        \n",
        "    # Ry\n",
        "    for name, theta in angles.items():\n",
        "      for t in targets:\n",
        "        key = 'Ry' + str(t) + '(' + name + ')'\n",
        "        gates[key] = QuantumGate(key, np.array([[math.cos(theta), -math.sin(theta)],\n",
        "                                                      [math.sin(theta), math.cos(theta)]]), t)\n",
        "        self._num_gates += 1\n",
        "\n",
        "    # Rz\n",
        "    for name, theta in angles.items():\n",
        "      for t in targets:\n",
        "        key = 'Rz' + str(t) + '(' + name + ')'\n",
        "        gates[key] = QuantumGate(key, np.array([[cmath.exp(-j*theta), 0],\n",
        "                                                      [0, cmath.exp(j*theta)]]), t)\n",
        "        self._num_gates += 1\n",
        "\n",
        "    self._mapping = list(gates.keys())\n",
        "    self._gates = list(gates.values())\n",
        "\n",
        "  def num_gates(self):\n",
        "    return self._num_gates"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQvWLKKRgZR9"
      },
      "source": [
        "#### Simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd9529db1c0b"
      },
      "source": [
        "try:\n",
        "    import cirq\n",
        "except ImportError:\n",
        "    print(\"installing cirq...\")\n",
        "    !pip install --quiet cirq\n",
        "    print(\"installed cirq.\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a4R9ebGj2rl"
      },
      "source": [
        "gates_pairs = [\n",
        "               (cirq.X, cirq.I),\n",
        "               (cirq.Y, cirq.I),\n",
        "               (cirq.Z, cirq.I),\n",
        "               (cirq.I, cirq.I), # CNOT not able to make it work\n",
        "               (cirq.rx(PI), cirq.I),\n",
        "               (cirq.I, cirq.rx(PI)),\n",
        "               (cirq.rx(2*PI/3), cirq.I),\n",
        "               (cirq.I, cirq.rx(2*PI/3)),\n",
        "               (cirq.rx(PI/2), cirq.I),\n",
        "               (cirq.I, cirq.rx(PI/2)),\n",
        "               (cirq.rx(PI/3), cirq.I),\n",
        "               (cirq.I, cirq.rx(PI/3)),\n",
        "               (cirq.rx(PI/4), cirq.I),\n",
        "               (cirq.I, cirq.rx(PI/4)),\n",
        "               (cirq.ry(PI), cirq.I),\n",
        "               (cirq.I, cirq.ry(PI)),\n",
        "               (cirq.ry(2*PI/3), cirq.I),\n",
        "               (cirq.I, cirq.ry(2*PI/3)),\n",
        "               (cirq.ry(PI/2), cirq.I),\n",
        "               (cirq.I, cirq.ry(PI/2)),\n",
        "               (cirq.ry(PI/3), cirq.I),\n",
        "               (cirq.I, cirq.ry(PI/3)),\n",
        "               (cirq.ry(PI/4), cirq.I),\n",
        "               (cirq.I, cirq.ry(PI/4)),\n",
        "               (cirq.rz(PI), cirq.I),\n",
        "               (cirq.I, cirq.rz(PI)),\n",
        "               (cirq.rz(2*PI/3), cirq.I),\n",
        "               (cirq.I, cirq.rz(2*PI/3)),\n",
        "               (cirq.rz(PI/2), cirq.I),\n",
        "               (cirq.I, cirq.rz(PI/2)),\n",
        "               (cirq.rz(PI/3), cirq.I),\n",
        "               (cirq.I, cirq.rz(PI/3)),\n",
        "               (cirq.rz(PI/4), cirq.I),\n",
        "               (cirq.I, cirq.rz(PI/4))\n",
        "]"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3c82c1c12a6"
      },
      "source": [
        "import cirq\n",
        "from cirq import Simulator\n",
        "\n",
        "PI = math.pi\n",
        "\n",
        "q0 = cirq.GridQubit(0, 0)\n",
        "q1 = cirq.GridQubit(1, 0)\n",
        "\n",
        "def basic_circuit(u1, u2):\n",
        "    yield u1(q0), u2(q1)\n",
        "\n",
        "# circuit = cirq.Circuit()\n",
        "# circuit.append(basic_circuit(cirq.CNOT(), cirq.I))\n",
        "\n",
        "# print(circuit)\n",
        "\n",
        "# simulator = Simulator()\n",
        "# result = simulator.simulate(circuit, qubit_order=[q0, q1])\n",
        "\n",
        "# print(result)\n",
        "# print(np.around(result.final_state_vector, 3))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A11rxMP0zlf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064ee9a9-eba8-4453-b15e-02823b495073"
      },
      "source": [
        "gates = Gates()\n",
        "\n",
        "# gates_pairs from Google QuantumAI\n",
        "for g, name, u in zip(gates._gates, gates._mapping, gates_pairs):\n",
        "  q = QuantumState(np.array([1, 0, 0, 0]))\n",
        "  old_amplitudes = q.get_amplitudes()\n",
        "  print(\"Gate \" + name)\n",
        "  q.apply_gate(g, inplace = True)\n",
        "  new_amplitudes = []\n",
        "  for val in q.get_amplitudes():\n",
        "    new_amplitudes.append(val)\n",
        "\n",
        "  print(\"Applied gate \" + name + f\" to qubit with amplitudes {old_amplitudes}.\\n\" +\n",
        "        f\"Updated amplitudes: {np.around(new_amplitudes, 3)}\")\n",
        "  \n",
        "  # Google QuantumAI simulation\n",
        "  circuit = cirq.Circuit()\n",
        "  circuit.append(basic_circuit(u[0], u[1]))\n",
        "\n",
        "  simulator = Simulator()\n",
        "  result = simulator.simulate(circuit, qubit_order=[q0, q1])\n",
        "  print(f\"Google QuantumAI: {np.around(result.final_state_vector, 3)}\")\n",
        "\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gate x0\n",
            "Applied gate x0 to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0 0 1 0]\n",
            "Google QuantumAI: [0.+0.j 0.+0.j 1.+0.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate y0\n",
            "Applied gate y0 to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.+0.j 0.+0.j 0.+1.j 0.+0.j]\n",
            "Google QuantumAI: [0.-0.j 0.-0.j 0.+1.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate z0\n",
            "Applied gate z0 to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [1 0 0 0]\n",
            "Google QuantumAI: [ 1.+0.j  0.+0.j -0.+0.j -0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate CNOT\n",
            "Applied gate CNOT to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [1 0 0 0]\n",
            "Google QuantumAI: [1.+0.j 0.+0.j 0.+0.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx0(pi)\n",
            "Applied gate Rx0(pi) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.+0.j 0.+0.j 0.-1.j 0.+0.j]\n",
            "Google QuantumAI: [0.+0.j 0.+0.j 0.-1.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx1(pi)\n",
            "Applied gate Rx1(pi) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.+0.j 0.-1.j 0.+0.j 0.+0.j]\n",
            "Google QuantumAI: [0.+0.j 0.-1.j 0.+0.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx0(2pi/3)\n",
            "Applied gate Rx0(2pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.5+0.j    0. +0.j    0. -0.866j 0. +0.j   ]\n",
            "Google QuantumAI: [0.5+0.j    0. +0.j    0. -0.866j 0. +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx1(2pi/3)\n",
            "Applied gate Rx1(2pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.5+0.j    0. -0.866j 0. +0.j    0. +0.j   ]\n",
            "Google QuantumAI: [0.5+0.j    0. -0.866j 0. +0.j    0. +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx0(pi/2)\n",
            "Applied gate Rx0(pi/2) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.707+0.j    0.   +0.j    0.   -0.707j 0.   +0.j   ]\n",
            "Google QuantumAI: [0.707+0.j    0.   +0.j    0.   -0.707j 0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx1(pi/2)\n",
            "Applied gate Rx1(pi/2) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.707+0.j    0.   -0.707j 0.   +0.j    0.   +0.j   ]\n",
            "Google QuantumAI: [0.707+0.j    0.   -0.707j 0.   +0.j    0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx0(pi/3)\n",
            "Applied gate Rx0(pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.866+0.j  0.   +0.j  0.   -0.5j 0.   +0.j ]\n",
            "Google QuantumAI: [0.866+0.j  0.   +0.j  0.   -0.5j 0.   +0.j ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx1(pi/3)\n",
            "Applied gate Rx1(pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.866+0.j  0.   -0.5j 0.   +0.j  0.   +0.j ]\n",
            "Google QuantumAI: [0.866+0.j  0.   -0.5j 0.   +0.j  0.   +0.j ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx0(pi/4)\n",
            "Applied gate Rx0(pi/4) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.924+0.j    0.   +0.j    0.   -0.383j 0.   +0.j   ]\n",
            "Google QuantumAI: [0.924+0.j    0.   +0.j    0.   -0.383j 0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rx1(pi/4)\n",
            "Applied gate Rx1(pi/4) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.924+0.j    0.   -0.383j 0.   +0.j    0.   +0.j   ]\n",
            "Google QuantumAI: [0.924+0.j    0.   -0.383j 0.   +0.j    0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry0(pi)\n",
            "Applied gate Ry0(pi) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0. 0. 1. 0.]\n",
            "Google QuantumAI: [0.-0.j 0.-0.j 1.+0.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry1(pi)\n",
            "Applied gate Ry1(pi) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0. 1. 0. 0.]\n",
            "Google QuantumAI: [0.-0.j 1.+0.j 0.-0.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry0(2pi/3)\n",
            "Applied gate Ry0(2pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.5   0.    0.866 0.   ]\n",
            "Google QuantumAI: [0.5  +0.j 0.   +0.j 0.866+0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry1(2pi/3)\n",
            "Applied gate Ry1(2pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.5   0.866 0.    0.   ]\n",
            "Google QuantumAI: [0.5  +0.j 0.866+0.j 0.   +0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry0(pi/2)\n",
            "Applied gate Ry0(pi/2) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.707 0.    0.707 0.   ]\n",
            "Google QuantumAI: [0.707+0.j 0.   +0.j 0.707+0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry1(pi/2)\n",
            "Applied gate Ry1(pi/2) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.707 0.707 0.    0.   ]\n",
            "Google QuantumAI: [0.707+0.j 0.707+0.j 0.   +0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry0(pi/3)\n",
            "Applied gate Ry0(pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.866 0.    0.5   0.   ]\n",
            "Google QuantumAI: [0.866+0.j 0.   +0.j 0.5  +0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry1(pi/3)\n",
            "Applied gate Ry1(pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.866 0.5   0.    0.   ]\n",
            "Google QuantumAI: [0.866+0.j 0.5  +0.j 0.   +0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry0(pi/4)\n",
            "Applied gate Ry0(pi/4) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.924 0.    0.383 0.   ]\n",
            "Google QuantumAI: [0.924+0.j 0.   +0.j 0.383+0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Ry1(pi/4)\n",
            "Applied gate Ry1(pi/4) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.924 0.383 0.    0.   ]\n",
            "Google QuantumAI: [0.924+0.j 0.383+0.j 0.   +0.j 0.   +0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz0(pi)\n",
            "Applied gate Rz0(pi) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.-1.j 0.+0.j 0.+0.j 0.+0.j]\n",
            "Google QuantumAI: [0.-1.j 0.+0.j 0.+0.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz1(pi)\n",
            "Applied gate Rz1(pi) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.-1.j 0.+0.j 0.+0.j 0.+0.j]\n",
            "Google QuantumAI: [0.-1.j 0.+0.j 0.+0.j 0.+0.j]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz0(2pi/3)\n",
            "Applied gate Rz0(2pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.5-0.866j 0. +0.j    0. +0.j    0. +0.j   ]\n",
            "Google QuantumAI: [0.5-0.866j 0. +0.j    0. +0.j    0. +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz1(2pi/3)\n",
            "Applied gate Rz1(2pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.5-0.866j 0. +0.j    0. +0.j    0. +0.j   ]\n",
            "Google QuantumAI: [0.5-0.866j 0. +0.j    0. +0.j    0. +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz0(pi/2)\n",
            "Applied gate Rz0(pi/2) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.707-0.707j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "Google QuantumAI: [0.707-0.707j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz1(pi/2)\n",
            "Applied gate Rz1(pi/2) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.707-0.707j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "Google QuantumAI: [0.707-0.707j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz0(pi/3)\n",
            "Applied gate Rz0(pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.866-0.5j 0.   +0.j  0.   +0.j  0.   +0.j ]\n",
            "Google QuantumAI: [0.866-0.5j 0.   +0.j  0.   +0.j  0.   +0.j ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz1(pi/3)\n",
            "Applied gate Rz1(pi/3) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.866-0.5j 0.   +0.j  0.   +0.j  0.   +0.j ]\n",
            "Google QuantumAI: [0.866-0.5j 0.   +0.j  0.   +0.j  0.   +0.j ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz0(pi/4)\n",
            "Applied gate Rz0(pi/4) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.924-0.383j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "Google QuantumAI: [0.924-0.383j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n",
            "Gate Rz1(pi/4)\n",
            "Applied gate Rz1(pi/4) to qubit with amplitudes [1 0 0 0].\n",
            "Updated amplitudes: [0.924-0.383j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "Google QuantumAI: [0.924-0.383j 0.   +0.j    0.   +0.j    0.   +0.j   ]\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQJvflImPuhP"
      },
      "source": [
        "# RL Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aflbZWf75E7C"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL6bfPeCJSbl"
      },
      "source": [
        "# LinearModel of the environment\n",
        "class LinearModel:\n",
        "  def __init__(self, initial_state, target_state, tolerance):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      initial_state (QuantumState): initial state of the system\n",
        "      target_state (QuantumState): target state of the system\n",
        "      tolerance (float): tolerance in terms of fidelity score\n",
        "    \"\"\"\n",
        "    self._initial_state = initial_state\n",
        "    self._target_state = target_state\n",
        "    self._tolerance = tolerance # tolerance in terms of fidelity between\n",
        "    self._quantum_gates, self._mapping, self._num_gates = self.gates_set()\n",
        "    self._terminal_fidelity = 0 # used to retrieve the info at the end of an episode\n",
        "    self._terminal_state = None # used to retrieve the info at the end of an episode\n",
        "    \n",
        "    # Used to initialize env from scratch.\n",
        "    self.reset() \n",
        "\n",
        "    assert initial_state.fidelity_score(target_state) < (1-tolerance), f\"The two state are the same up to {tolerance} tolerance\"\n",
        "\n",
        "    \n",
        "  def gates_set(self):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      gates._gates (List[QuantumGate]): return the list with available QuantumGate objects\n",
        "      gates._mapping (Dict[String: Int]): dicitonary mapping a gate to its action index\n",
        "      gates.num_gates() (int): number of available gates (actions)\n",
        "    \"\"\"\n",
        "    gates = Gates()\n",
        "    return gates._gates, gates._mapping, gates.num_gates()\n",
        "\n",
        "  def step(self, action):\n",
        "    \"\"\"\n",
        "    Given a gate, apply it to self._state.\n",
        "    Set the reward, resulting state and discount.\n",
        "    Return these values, along with the information if therminal state has been reached\n",
        "    Args:\n",
        "      action (int): action index to select a QuantumGate\n",
        "\n",
        "    Return:\n",
        "      reward, discount, next_state features, terminal\n",
        "    \"\"\"\n",
        "    # Get and apply action. next_state is a QuantumState\n",
        "    gate = self._quantum_gates[action]\n",
        "    next_state = self._state.apply_gate(gate)\n",
        "\n",
        "    # Compare new state and target\n",
        "    fidelity = next_state.fidelity_score(self._target_state)\n",
        "\n",
        "    # Assign reward based on state and fidelity\n",
        "    terminal = self.is_terminal(fidelity)\n",
        "\n",
        "    # Terminal state\n",
        "    if terminal:\n",
        "      reward = +100.\n",
        "      discount = 0.\n",
        "      self._terminal_fidelity = fidelity\n",
        "      self._terminal_state = next_state\n",
        "      self.reset()\n",
        "    else:\n",
        "      reward = -6.\n",
        "      discount = 0.9\n",
        "      self._current_fidelity = fidelity\n",
        "      self._state = next_state\n",
        "\n",
        "\n",
        "    # Return the features, not the state itself\n",
        "    return reward, discount, self.get_obs(), terminal\n",
        "\n",
        "\n",
        "  def is_terminal(self, fidelity):\n",
        "    \"\"\"\n",
        "    Check if, by a level of self.tolerance, state is terminal\n",
        "    \"\"\"\n",
        "    if fidelity > (1 - self._tolerance):\n",
        "      return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "  def get_obs(self):\n",
        "    return self._state.get_features()\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self._state = self._initial_state\n",
        "    self._current_fidelity = 0"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ZoAqcy3qkH"
      },
      "source": [
        "## Agent\n",
        "There is a bug I think, when I provide as next_state the initial state I\n",
        "- agent is in state self._state: a state contiguous to the terminal one, T, that we call S\n",
        "- the update is done for S wrt to next_state, which in this case is I, and not T as expected. There are 2 major drawbacks as consequence  \n",
        "One is that the update is done wrongly: r + g*q(I), but I here has not any sense\n",
        "Two is that I will never learn that this state is contiguous.\n",
        "\n",
        "Now, I have to reason about this, because I think in the assignment they used this approach, but better to write down this doubt.\n",
        "\n",
        "NO! This issue is fixed by putting discount = 0. Alright :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWp0UZ7q6VVF"
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.buffer = []\n",
        "  \n",
        "  def append_transition(self, transition):\n",
        "    self.buffer.append(transition)\n",
        "\n",
        "  def sample_transition(self):\n",
        "    return random.choice(self.buffer)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De-sHIvHwKra"
      },
      "source": [
        "# Least Square TD Agent: action value function approximation\n",
        "# implemented with gradient descent.\n",
        "class LSTDAgent:\n",
        "  def __init__(self, number_of_actions, number_of_features,\n",
        "      initial_state, step_size, num_offline_updates):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      initial_state: it is a feature vector!\n",
        "    \"\"\"\n",
        "    self._number_of_actions = number_of_actions\n",
        "    self._W = np.zeros((number_of_actions, number_of_features))\n",
        "    self._step_size = step_size\n",
        "    self._state = initial_state\n",
        "    self._action = 17\n",
        "\n",
        "    self._num_offline_updates = num_offline_updates\n",
        "    self._replay_buffer = ReplayBuffer() # supervised dataset\n",
        "\n",
        "  def behaviour_policy(self, state = None):\n",
        "    # greedy = np.random.choice([True, False], p=[1-self._eps, self._eps])\n",
        "    # if greedy:\n",
        "    #   return np.argmax(self.q(state))\n",
        "    return random.choice(range(self._number_of_actions))\n",
        "\n",
        "  def q(self, state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      state (list): list of the amplitudes := features of the state\n",
        "    \"\"\"\n",
        "    return np.matmul(self._W, state)\n",
        "\n",
        "  def step(self, reward, discount, next_state):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      next_state (list): list of the amplitude: these are already features, not a QuantumState instance\n",
        "      terminal (boolean): if next_state is the terminal state\n",
        "    \"\"\"\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    r = reward\n",
        "    next_s = next_state\n",
        "    g = discount\n",
        "\n",
        "    self._W[a] += self._step_size * (r + g * np.max(self.q(next_s)) - self.q(s)[a]) * s\n",
        "\n",
        "    # Experience replay\n",
        "    self._replay_buffer.append_transition((s, a, r, g, next_s))\n",
        "    for _ in range(self._num_offline_updates):\n",
        "      s, a, r, g, next_s = self._replay_buffer.sample_transition()\n",
        "      self._W[a] += self._step_size * (r + g * np.max(self.q(next_s)) - self.q(s)[a]) * s\n",
        "\n",
        "    next_a = self.behaviour_policy()\n",
        "    self._action = next_a\n",
        "    self._state = next_s\n",
        "\n",
        "    return next_a\n",
        "\n",
        "  def inference(self, reward, discount, next_state):\n",
        "    s = self._state\n",
        "    a = self._action\n",
        "    r = reward\n",
        "    next_s = next_state\n",
        "    g = discount\n",
        "\n",
        "    next_a = np.argmax(self.q(next_s))\n",
        "    self._action = next_a\n",
        "    self._state = next_s\n",
        "\n",
        "    return next_a"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFL1yPnM06xH"
      },
      "source": [
        "# Experiment Facade and Helper Functions\n",
        "Class to handle experiments and visualization  \n",
        "- [X] run experiment\n",
        "- [ ] Allow for agent.q visualization for a state, providing labels to actions. This allow to see if very close states are associated to very close actions\n",
        "- [ ] Monitor number of steps as experience grow: is the agent actually learning good? ==> in this sense no, but this is because of local minima. I do not have guaranteee to find a global otimum with gradient descent (verify)\n",
        "- [ ] Monitor the weights (see if I can find any meaning): need to put labels about actions ==> does an action focuses on an amplitudes subset as I would expect (e.g. if an amplitude is not touched by  gate, than I expect its weight value to be low\n",
        "- [X] Monitor fidelity score inside episodes --> add inference every N steps\n",
        "- [ ] Monitor impact of initial gate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfMBR8Ws0sqy"
      },
      "source": [
        "# Facade class to run experiment\n",
        "class Experiment:\n",
        "  def __init__(self, start_state, target_state, tolerance, number_of_episodes, step_size, num_offline_updates, inference_ratio = 200):\n",
        "\n",
        "    self._env = LinearModel(QuantumState(start_state), QuantumState(target_state), tolerance)\n",
        "\n",
        "    number_of_actions = len(self._env._mapping)\n",
        "    initial_features = self._env.get_obs()\n",
        "\n",
        "    self._agent = LSTDAgent(number_of_actions, len(initial_features), initial_features,\n",
        "                            step_size, num_offline_updates)\n",
        "    \n",
        "    self._number_of_episodes = number_of_episodes\n",
        "\n",
        "    self._episodes_gates = [] # check disrtribution of gates in different solutions\n",
        "    self._mean_rewards = [] # list of mean reward for each episode\n",
        "    self._inference_ratio = inference_ratio # run an inference episode every inference_ratio training episodes\n",
        "    self._successes = 0\n",
        "\n",
        "\n",
        "  def run_experiment(self):\n",
        "    \"\"\"\n",
        "    Run episodes, gathering statistics and updating user on conosole.\n",
        "    \"\"\"\n",
        "    # Run inference on 1 out of inference_ratio training episodes\n",
        "    inference_gates = []\n",
        "    for episode in range(self._number_of_episodes):\n",
        "      self.run_episode()\n",
        "      # if episode % self._inference_ratio == 0:\n",
        "      inference_gates.append(self.run_inference(episode))\n",
        "\n",
        "    inference_gates.append(self.run_inference(episode))\n",
        "\n",
        "    return inference_gates\n",
        "\n",
        "\n",
        "  def run_episode(self):\n",
        "    \"\"\"\n",
        "    Run a single episode.\n",
        "    At the beginning of an episode we must guarantee\n",
        "    - initial state in the environment\n",
        "    - initial state in the agent\n",
        "    \"\"\"\n",
        "    terminal = False\n",
        "    action = self._agent._action\n",
        "    while not terminal:\n",
        "      reward, discount, next_s, terminal = self._env.step(action)\n",
        "      action = self._agent.step(reward, discount, next_s)\n",
        "\n",
        "\n",
        "  def run_inference(self, episode):\n",
        "    \"\"\"\n",
        "    Run an episode using the optimal policy learned\n",
        "    \"\"\"\n",
        "    terminal = False\n",
        "    action = self._agent._action\n",
        "    gates = [action]\n",
        "    while not terminal and len(gates) <= 1000:\n",
        "      reward, discount, next_s, terminal = self._env.step(action)\n",
        "      action = self._agent.inference(reward, discount, next_s)\n",
        "      gates.append(action)\n",
        "\n",
        "    max_gates = 20\n",
        "    if len(gates) >= max_gates:\n",
        "      # print(f\"Couldn't reach target in less than {max_gates} steps. Current fidelity {self._env._current_fidelity}.\")\n",
        "      return gates\n",
        "\n",
        "    # self._agent._step_size *= .1\n",
        "    self._successes += 1\n",
        "    print(f\"Episode {episode}: inference completed in {len(gates)} steps. Fidelity score: {self._env._terminal_fidelity}\")\n",
        "\n",
        "    return gates\n",
        "\n",
        "  \n",
        "  def q_values(self):\n",
        "    \"\"\"\n",
        "    The function should plot, in a [0, 1] complex plane, the value function\n",
        "    on the z axis, for each of the 4 value of amplitude.\n",
        "    In order to get reasonable values and understand the effect of the amplitude\n",
        "    under analysis on the overall q_values, the remaining amplitudes values will \n",
        "    be set to the target amplitudes.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
        "\n",
        "    state = self._env._target_state\n",
        "    features = state.get_features()\n",
        "    x = np.linspace(0, 1, num=100)\n",
        "    y = np.linspace(0, 1, num=100)\n",
        "    grid = np.meshgrid\n",
        "    q = []\n",
        "    for i in x:\n",
        "      row = []\n",
        "      for k in y:\n",
        "        features[0] = i\n",
        "        features[0] = k\n",
        "        row.append(self._agent.q(features))\n",
        "      \n",
        "      q.append(row)\n",
        "\n",
        "    q = np.array(q)\n",
        "    surf = ax.plot_surface(x, y, np.squeeze(q[:, :, 0]), cmap=cm.coolwarm,\n",
        "                       linewidth=0, antialiased=False)\n",
        "    \n",
        "    # Add a color bar which maps values to colors.\n",
        "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YKa4MYQ0tUp"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN0SmXxG_LPx"
      },
      "source": [
        "- Need to tune all the parameters below. In particular, it is important to understand upt to which point we can decrease the tolerance.\n",
        "- Substitute TRAINING_EPISODES with number of training steps "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW1bekJrCTYu"
      },
      "source": [
        "# Run an inference every N episodes and monitor the optimality of the behaviour\n",
        "# We could add experience replay, since after a certain number of new episodes it doesn't work well anymore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mlv4JNv2Vs7"
      },
      "source": [
        "Compare \n",
        "- Step size decrease (che e un concettoesistente in Deep lr ==> scheduler): è migliorativo?\n",
        "- behavioural policy: random o eps greedy?\n",
        "- Different rewards\n",
        "- Ragionare su perché il miglioramente non è costante, come invece vorrei,\n",
        "==> ho bisogno di generalizzare? no devo essere di successo solo su cio che ho visto in training\n",
        "Behaviour policy always exploring has been solution: try without.\n",
        "Nota: la ragione del comportamento oscillante da episodio a episodio è dovuto al fatto che gradient descent rischia di cadere in local optima ==> rallenta la convergenza a una policy ottimale. Quanto invece ho dei buoni seed esco di lì. \n",
        "Devo mediare o cosa? Posso anche mediare, ma dire che a noi serve un global optimum per trovare l'optimal path, non generalizzare. Chiedo a tizio.\n",
        "\n",
        "- Comparo diverse target policy da diversi behaviour!\n",
        "- testare experience replay per capire al meglio ogni stato. ==> mi serve o posso togliere?\n",
        "- Comparo numero di policy di successo rispetto a un approccio random: però la policy che imparo è imparata, il random no, cretino ==> quindi anche se e peggio in generale, basta sia buono una volta. Probabilmente il minimo che trovo è oslo locale, ma è gia sufficiente, e il fatto che ne esca continuamente richiede soluzione a piu ampio spettro a cui non sono interessato ora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWUAwhF9A104"
      },
      "source": [
        "Non appena apprendo una policy che in meno di N gates mi da' l'accuracy desiderata, la mia tesi è finita capo. Quindi ci sono già. In questo momento è importatne garamntire che una sola votlta, prima o poi, funziona. E questo sono in grado di farlo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R5nEorB3kgW"
      },
      "source": [
        "TOLERANCE = 0.1\n",
        "TRAINING_EPISODES = 100000\n",
        "STEP_SIZE = 0.0001\n",
        "NUM_OFFLINE_UPDATES = 0 # Better remove it, I guess, we'll see"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b2pDqPiVFxp",
        "outputId": "e8046d87-57f5-48bc-aa4b-b7c3161502d1"
      },
      "source": [
        "%%time\n",
        "target = [0.5, 0.5, 0.5, 0.5]\n",
        "start = [0.1j, 0.1, 0.1, -0.985]\n",
        "experiment = Experiment(start, target, TOLERANCE, TRAINING_EPISODES, STEP_SIZE, NUM_OFFLINE_UPDATES)\n",
        "gates_sequences = experiment.run_experiment()\n",
        "len_sequences = list(map(lambda x: len(x), gates_sequences))\n",
        "print()\n",
        "print(experiment._successes)\n",
        "sns.heatmap(experiment._agent._W)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode 4: inference completed in 7 steps. Fidelity score: 0.9059021216744562\n",
            "Episode 27: inference completed in 18 steps. Fidelity score: 0.922526366244911\n",
            "Episode 46: inference completed in 11 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 48: inference completed in 11 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 56: inference completed in 15 steps. Fidelity score: 0.9346633116895158\n",
            "Episode 71: inference completed in 16 steps. Fidelity score: 0.9070148846906092\n",
            "Episode 76: inference completed in 8 steps. Fidelity score: 0.9702250000000002\n",
            "Episode 134: inference completed in 18 steps. Fidelity score: 0.9493010145764706\n",
            "Episode 140: inference completed in 18 steps. Fidelity score: 0.9022953450805304\n",
            "Episode 145: inference completed in 13 steps. Fidelity score: 0.9493010145764704\n",
            "Episode 155: inference completed in 19 steps. Fidelity score: 0.9493010145764702\n",
            "Episode 156: inference completed in 12 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 158: inference completed in 18 steps. Fidelity score: 0.9014153076777055\n",
            "Episode 159: inference completed in 13 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 194: inference completed in 9 steps. Fidelity score: 0.9702250000000002\n",
            "Episode 195: inference completed in 13 steps. Fidelity score: 0.9393062808230549\n",
            "Episode 198: inference completed in 9 steps. Fidelity score: 0.9702250000000002\n",
            "Episode 206: inference completed in 15 steps. Fidelity score: 0.9059021216744554\n",
            "Episode 213: inference completed in 15 steps. Fidelity score: 0.9283718873316116\n",
            "Episode 227: inference completed in 8 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 234: inference completed in 16 steps. Fidelity score: 0.9358388121378264\n",
            "Episode 236: inference completed in 19 steps. Fidelity score: 0.9702250000000002\n",
            "Episode 241: inference completed in 15 steps. Fidelity score: 0.9059021216744556\n",
            "Episode 243: inference completed in 10 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 250: inference completed in 18 steps. Fidelity score: 0.9188173271828853\n",
            "Episode 262: inference completed in 17 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 265: inference completed in 13 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 282: inference completed in 13 steps. Fidelity score: 0.9390398103108403\n",
            "Episode 310: inference completed in 9 steps. Fidelity score: 0.9551521216744563\n",
            "Episode 318: inference completed in 11 steps. Fidelity score: 0.9059021216744562\n",
            "Episode 323: inference completed in 13 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 326: inference completed in 16 steps. Fidelity score: 0.9276970923922261\n",
            "Episode 349: inference completed in 9 steps. Fidelity score: 0.9022737599532861\n",
            "Episode 351: inference completed in 9 steps. Fidelity score: 0.9022737599532861\n",
            "Episode 356: inference completed in 19 steps. Fidelity score: 0.9170839744210202\n",
            "Episode 361: inference completed in 10 steps. Fidelity score: 0.9551521216744565\n",
            "Episode 369: inference completed in 9 steps. Fidelity score: 0.925909350095958\n",
            "Episode 386: inference completed in 11 steps. Fidelity score: 0.9305271216744563\n",
            "Episode 393: inference completed in 10 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 398: inference completed in 9 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 417: inference completed in 8 steps. Fidelity score: 0.9390398103108403\n",
            "Episode 424: inference completed in 9 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 440: inference completed in 8 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 455: inference completed in 16 steps. Fidelity score: 0.953473968619193\n",
            "Episode 460: inference completed in 17 steps. Fidelity score: 0.9263923738203014\n",
            "Episode 465: inference completed in 17 steps. Fidelity score: 0.9263923738203014\n",
            "Episode 486: inference completed in 17 steps. Fidelity score: 0.9002445671471695\n",
            "Episode 501: inference completed in 15 steps. Fidelity score: 0.9376826381367955\n",
            "Episode 519: inference completed in 17 steps. Fidelity score: 0.9002445671471695\n",
            "Episode 520: inference completed in 11 steps. Fidelity score: 0.9141745017045753\n",
            "Episode 566: inference completed in 8 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 576: inference completed in 12 steps. Fidelity score: 0.9044249586486621\n",
            "Episode 586: inference completed in 10 steps. Fidelity score: 0.9059021216744562\n",
            "Episode 590: inference completed in 18 steps. Fidelity score: 0.9056315083264173\n",
            "Episode 594: inference completed in 8 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 604: inference completed in 10 steps. Fidelity score: 0.970225\n",
            "Episode 610: inference completed in 17 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 611: inference completed in 16 steps. Fidelity score: 0.9305271216744565\n",
            "Episode 613: inference completed in 17 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 626: inference completed in 18 steps. Fidelity score: 0.9148851747204795\n",
            "Episode 629: inference completed in 13 steps. Fidelity score: 0.9551521216744563\n",
            "Episode 631: inference completed in 14 steps. Fidelity score: 0.9551521216744563\n",
            "Episode 639: inference completed in 10 steps. Fidelity score: 0.9059021216744558\n",
            "Episode 643: inference completed in 6 steps. Fidelity score: 0.9390398103108396\n",
            "Episode 646: inference completed in 11 steps. Fidelity score: 0.970225\n",
            "Episode 651: inference completed in 10 steps. Fidelity score: 0.970225\n",
            "Episode 657: inference completed in 10 steps. Fidelity score: 0.9551521216744563\n",
            "Episode 664: inference completed in 12 steps. Fidelity score: 0.9551521216744563\n",
            "Episode 669: inference completed in 8 steps. Fidelity score: 0.9059021216744562\n",
            "Episode 670: inference completed in 12 steps. Fidelity score: 0.9551521216744563\n",
            "Episode 671: inference completed in 10 steps. Fidelity score: 0.9634824539709854\n",
            "Episode 676: inference completed in 11 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 684: inference completed in 9 steps. Fidelity score: 0.9263923738203012\n",
            "Episode 689: inference completed in 12 steps. Fidelity score: 0.970225\n",
            "Episode 698: inference completed in 19 steps. Fidelity score: 0.9174634168577754\n",
            "Episode 719: inference completed in 17 steps. Fidelity score: 0.9759437342763486\n",
            "Episode 726: inference completed in 16 steps. Fidelity score: 0.9084366059429262\n",
            "Episode 739: inference completed in 9 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 748: inference completed in 11 steps. Fidelity score: 0.970225\n",
            "Episode 759: inference completed in 7 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 772: inference completed in 18 steps. Fidelity score: 0.9475619847989715\n",
            "Episode 779: inference completed in 19 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 788: inference completed in 15 steps. Fidelity score: 0.9059021216744559\n",
            "Episode 794: inference completed in 11 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 796: inference completed in 12 steps. Fidelity score: 0.9305271216744565\n",
            "Episode 799: inference completed in 10 steps. Fidelity score: 0.9283718873316118\n",
            "Episode 806: inference completed in 10 steps. Fidelity score: 0.9551521216744558\n",
            "Episode 815: inference completed in 13 steps. Fidelity score: 0.9702249999999993\n",
            "Episode 817: inference completed in 12 steps. Fidelity score: 0.9305271216744561\n",
            "Episode 831: inference completed in 11 steps. Fidelity score: 0.9305271216744565\n",
            "Episode 833: inference completed in 11 steps. Fidelity score: 0.9551521216744563\n",
            "Episode 840: inference completed in 8 steps. Fidelity score: 0.9551521216744565\n",
            "Episode 865: inference completed in 10 steps. Fidelity score: 0.9390398103108394\n",
            "Episode 867: inference completed in 16 steps. Fidelity score: 0.9455962777568125\n",
            "Episode 887: inference completed in 15 steps. Fidelity score: 0.9455962777568125\n",
            "Episode 892: inference completed in 13 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 950: inference completed in 9 steps. Fidelity score: 0.9067783133875135\n",
            "Episode 967: inference completed in 10 steps. Fidelity score: 0.9634824539709852\n",
            "Episode 982: inference completed in 19 steps. Fidelity score: 0.9393062808230549\n",
            "Episode 997: inference completed in 15 steps. Fidelity score: 0.9305271216744565\n",
            "Episode 1014: inference completed in 12 steps. Fidelity score: 0.930924874152141\n",
            "Episode 1016: inference completed in 12 steps. Fidelity score: 0.904486371233187\n",
            "Episode 1017: inference completed in 12 steps. Fidelity score: 0.930924874152141\n",
            "Episode 1019: inference completed in 7 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 1020: inference completed in 9 steps. Fidelity score: 0.9702250000000002\n",
            "Episode 1021: inference completed in 12 steps. Fidelity score: 0.904486371233187\n",
            "Episode 1023: inference completed in 7 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 1060: inference completed in 19 steps. Fidelity score: 0.9294697151209071\n",
            "Episode 1065: inference completed in 7 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 1071: inference completed in 7 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 1072: inference completed in 14 steps. Fidelity score: 0.9329871926028612\n",
            "Episode 1074: inference completed in 17 steps. Fidelity score: 0.9445467839290742\n",
            "Episode 1080: inference completed in 12 steps. Fidelity score: 0.9079658784659341\n",
            "Episode 1087: inference completed in 12 steps. Fidelity score: 0.9234797849566205\n",
            "Episode 1093: inference completed in 7 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 1103: inference completed in 15 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 1112: inference completed in 10 steps. Fidelity score: 0.95222062727821\n",
            "Episode 1115: inference completed in 19 steps. Fidelity score: 0.9514824224485685\n",
            "Episode 1125: inference completed in 10 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 1127: inference completed in 11 steps. Fidelity score: 0.940704876912897\n",
            "Episode 1130: inference completed in 15 steps. Fidelity score: 0.9538655632742102\n",
            "Episode 1147: inference completed in 11 steps. Fidelity score: 0.940704876912897\n",
            "Episode 1152: inference completed in 9 steps. Fidelity score: 0.9702249999999998\n",
            "Episode 1157: inference completed in 10 steps. Fidelity score: 0.9702250000000002\n",
            "Episode 1169: inference completed in 7 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 1173: inference completed in 7 steps. Fidelity score: 0.9551521216744561\n",
            "Episode 1183: inference completed in 12 steps. Fidelity score: 0.9485538728108398\n",
            "Episode 1185: inference completed in 14 steps. Fidelity score: 0.9283718873316118\n",
            "Episode 1205: inference completed in 16 steps. Fidelity score: 0.9393062808230545\n",
            "Episode 1206: inference completed in 13 steps. Fidelity score: 0.9702249999999991\n",
            "Episode 1282: inference completed in 17 steps. Fidelity score: 0.9044863712331872\n",
            "Episode 1321: inference completed in 15 steps. Fidelity score: 0.9145430971114465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5-DR4p_QJ8o"
      },
      "source": [
        "# Count the number of successes.\n",
        "# Some summary statistics of this type using binning should be plotted\n",
        "# In general this could be useful to compare different polcies\n",
        "# Please build a systematic set up\n",
        "lengths = []\n",
        "good_gates = []\n",
        "for el in gates_sequences:\n",
        "  if len(el) < 20:\n",
        "    good_gates.append(el)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t69RB72Nor3"
      },
      "source": [
        "for i in range(len(good_gates)):\n",
        "  good_gates[i] = list(map(lambda x: experiment._env._mapping[x], good_gates[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nzu_kr3-fr7",
        "outputId": "b79db7de-2d22-4759-c3c7-11cc8d3fc75e"
      },
      "source": [
        "good_gates"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Ry0(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry1(2pi/3)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx0(pi)',\n",
              "  'Rz1(2pi/3)',\n",
              "  'Ry1(pi/2)',\n",
              "  'Ry1(pi)',\n",
              "  'Rx1(2pi/3)',\n",
              "  'Ry1(pi)',\n",
              "  'Ry0(pi)',\n",
              "  'Rz1(pi/3)'],\n",
              " ['Ry0(2pi/3)',\n",
              "  'Rx1(pi/2)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz0(pi)',\n",
              "  'Rz1(pi/2)',\n",
              "  'Rz0(pi/3)',\n",
              "  'Rz1(2pi/3)'],\n",
              " ['Rx1(pi/4)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry0(pi)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz1(2pi/3)',\n",
              "  'CNOT'],\n",
              " ['Ry1(pi/2)',\n",
              "  'CNOT',\n",
              "  'Rz0(2pi/3)',\n",
              "  'Ry0(2pi/3)',\n",
              "  'Ry0(pi/3)',\n",
              "  'Ry1(pi/2)',\n",
              "  'Rz0(2pi/3)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz1(2pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'CNOT'],\n",
              " ['CNOT',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rz0(pi)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(2pi/3)',\n",
              "  'Rz0(2pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'CNOT'],\n",
              " ['Rx1(pi)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Rx0(pi/3)',\n",
              "  'Rz0(pi)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(2pi/3)'],\n",
              " ['Ry1(pi/3)',\n",
              "  'Rx1(2pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz1(pi/2)',\n",
              "  'Rz1(pi/2)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'CNOT'],\n",
              " ['Ry1(pi/2)',\n",
              "  'Rx1(2pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz1(pi/2)',\n",
              "  'Rz1(pi/2)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Rx1(2pi/3)'],\n",
              " ['CNOT',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rx1(pi/2)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Rz1(pi/3)',\n",
              "  'CNOT'],\n",
              " ['Rx0(pi)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Rz0(pi)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Ry1(pi/3)',\n",
              "  'Ry1(pi/3)',\n",
              "  'Ry1(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(pi/3)'],\n",
              " ['Ry0(pi/3)',\n",
              "  'Rx1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rx1(pi)',\n",
              "  'Ry1(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(pi/3)'],\n",
              " ['Rz0(pi/4)',\n",
              "  'Rx1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rx1(pi)',\n",
              "  'Ry1(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(pi/3)'],\n",
              " ['Rx1(pi/4)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rx1(pi)',\n",
              "  'Ry1(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(pi/3)'],\n",
              " ['Ry1(pi/4)',\n",
              "  'CNOT',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz1(pi/2)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'Ry0(pi/4)',\n",
              "  'CNOT'],\n",
              " ['Ry0(pi/3)',\n",
              "  'Ry1(pi)',\n",
              "  'Rx1(pi/2)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Rz1(pi/4)',\n",
              "  'Rz0(pi/3)',\n",
              "  'Rz1(pi)',\n",
              "  'Rz1(2pi/3)',\n",
              "  'Rz1(2pi/3)',\n",
              "  'Rz1(pi/3)',\n",
              "  'Rz0(2pi/3)',\n",
              "  'Rx1(pi)',\n",
              "  'Ry1(pi/3)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(pi/3)'],\n",
              " ['Rz0(pi/4)',\n",
              "  'Ry0(pi/2)',\n",
              "  'Rz0(2pi/3)',\n",
              "  'Rz0(pi/4)',\n",
              "  'Rx1(pi)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Ry1(pi/4)',\n",
              "  'Rx1(pi/3)']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy2c4fkW4QCC",
        "outputId": "bef57749-c973-4f16-f9fd-fef4ac2f59e5"
      },
      "source": [
        "experiment._env._terminal_state.get_amplitudes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.70876626+0.01913417j, -0.38731851-0.04619398j,\n",
              "       -0.51588681-0.03314136j, -0.26780692+0.08001031j])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pss1hqFz3G_",
        "outputId": "cb708b77-5127-497e-d7f7-41595de71b87"
      },
      "source": [
        "experiment._env._terminal_state.fidelity_score(experiment._env._target_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.856652121674456"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0Tz6BuBybfY",
        "outputId": "6efea5e7-16c1-46f6-f54d-3730158abb5e"
      },
      "source": [
        "len(experiment.run_inference()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}